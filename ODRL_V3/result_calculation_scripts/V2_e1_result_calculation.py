import asyncio
import json
import os
from pathlib import Path
from typing import List, Dict, TypedDict, Any
from collections import defaultdict

# --- Langchain & LangGraph æ ¸å¿ƒç»„ä»¶ ---
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END

# --- å¯¼å…¥æ‚¨çš„çœŸå®æ¨¡å— ---
from mongodb import MongoDBManager
from ODRL_Check import validate_odrl_against_shacl

# --- ç”¨æˆ·éœ€è¦é…ç½®çš„å¸¸é‡ ---

# MongoDB é…ç½®
MONGO_URI = "mongodb://localhost:27017/"
MONGO_DB_NAME = "odrl3_final"
COLLECTION_NAME = "e1_41"

# OpenAI API Key (è¯·ç¡®ä¿ç¯å¢ƒå˜é‡ OPENAI_API_KEY å·²è®¾ç½®)
# æˆ–è€…å–æ¶ˆä¸‹ä¸€è¡Œæ³¨é‡Šå¹¶æä¾›æ–‡ä»¶è·¯å¾„
API_KEY_PATH = r"C:\Users\34085\Desktop\Agent\ALL_API_KEY.txt"

# SHACL æ–‡ä»¶è·¯å¾„ (çœŸå®è·¯å¾„)
SHACL_PATHS = {
    "set": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Rule_Shapes.ttl",
    "offer": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Offer_Shape.ttl",
    "agreement": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Agreement_Shape.ttl",
}

# ODRL ç±»å‹å¯¹åº”çš„æ€»çº¦æŸæ•°é‡
TOTAL_CONSTRAINTS_BY_TYPE = {
    "set": 29,
    "offer": 23,
    "agreement": 24,
}

# ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„
OUTPUT_RESULTS_PATH = Path(r"ODRL_V3\result\3e\e1_41_r3.json")

# å®šä¹‰éœ€è¦è¯„ä¼°çš„ ODRL ç­–ç•¥å­—æ®µå (ä¸Mongoæ–‡æ¡£å­—æ®µå®Œå…¨å¯¹åº”)
ODRL_STRATEGIES = {
    "ontology": 'initial_odrl',
    "vldb": 'final_odrl_branch_A_constraint',
    "vldb_semantic": 'enhanced_odrl_after_constraint',
    "semantic_syntactic": 'final_odrl_branch_B_validation'
}

# LLM è£åˆ¤å›¢é…ç½®
LLM_JUDGE_COUNT = 2

# æ–°å¢ï¼šå…¨å±€æœ€å¤§å¹¶å‘æ•°é‡æ§åˆ¶
# I/Oå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚APIè°ƒç”¨ï¼‰çš„å¹¶å‘é™åˆ¶
MAX_IO_CONCURRENCY = 50
io_semaphore = asyncio.Semaphore(MAX_IO_CONCURRENCY)

# CPUå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚SHACLéªŒè¯ï¼‰çš„å¹¶å‘é™åˆ¶
# é€šå¸¸è®¾ç½®ä¸ºæœºå™¨çš„CPUæ ¸å¿ƒæ•°
MAX_CPU_CONCURRENCY = 8
cpu_semaphore = asyncio.Semaphore(MAX_CPU_CONCURRENCY)

async def return_zero() -> float:
    """ä¸€ä¸ªç®€å•çš„å¼‚æ­¥å‡½æ•°ï¼Œç”¨äºåœ¨æ£€æµ‹åˆ°æ— æ•ˆODRLæ—¶è¿”å›0.0åˆ†ã€‚"""
    return 0.0

# --- Pydantic æ¨¡å‹å®šä¹‰ (å¤ç”¨è‡ªåŸä»£ç ) ---
class SemanticEvaluation(BaseModel):
    """ç”¨äºè§„èŒƒè¯­ä¹‰è¯„ä¼°ç»“æœçš„æ•°æ®ç»“æ„ï¼Œç¬¦åˆè¯­ä¹‰ä¸€è‡´æ€§å¾—åˆ†è®¡ç®—é€»è¾‘"""
    total_semantic_units: int = Field(
        ...,
        description="ä»åŸå§‹policyæ–‡æœ¬ä¸­åˆ†æå‡ºçš„æ‰€æœ‰ç‹¬ç«‹è¯­ä¹‰ç‚¹çš„æ€»æ•°é‡ã€‚æ¯ä¸ªè¯­ä¹‰ç‚¹ä»£è¡¨policyä¸­çš„ä¸€ä¸ªå…³é”®ä¿¡æ¯å…ƒç´ ï¼ˆå®ä½“ã€è§„åˆ™ã€æ¡ä»¶ã€å±æ€§ç­‰ï¼‰ï¼Œä¸”ä¸å¯å†åˆ†"
    )
    correctly_reflected_units: int = Field(
        ...,
        description="åœ¨ODRLç­–ç•¥ä¸­è¢«å‡†ç¡®ã€å®Œæ•´è¡¨è¾¾å‡ºæ¥çš„è¯­ä¹‰ç‚¹çš„æ•°é‡ã€‚å‡†ç¡®è¡¨è¾¾æŒ‡ODRLä¸­æœ‰å¯¹åº”å…ƒç´ ä¸”è¯­ä¹‰ä¸€è‡´"
    )
    missing_or_incorrect_units: List[str] = Field(
        ...,
        description="æœªè¢«æ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹æè¿°åˆ—è¡¨ï¼Œè¯´æ˜å“ªäº›è¯­ä¹‰ç‚¹åœ¨ODRLä¸­ç¼ºå¤±æˆ–è¡¨è¾¾é”™è¯¯"
    )

# --- Prompt å®šä¹‰ (å¤ç”¨è‡ªåŸä»£ç ) ---
SEMANTIC_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
"""
æ‚¨æ˜¯ä¸€ä½ç²¾é€šODRLå’Œè‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸“å®¶ã€‚æ‚¨çš„ä»»åŠ¡æ˜¯ç²¾ç¡®è¯„ä¼°ç»™å®šçš„ODRLç­–ç•¥æ˜¯å¦å‡†ç¡®åæ˜ äº†åŸå§‹Policyæ–‡æœ¬ä¸­çš„æ‰€æœ‰è¯­ä¹‰ç‚¹ã€‚

**æ ¸å¿ƒä»»åŠ¡ï¼š**
1.  **è¯†åˆ«è¯­ä¹‰ç‚¹**: ä¸¥æ ¼éµå¾ªä¸‹è¿°çš„ **â€œè¯­ä¹‰ç‚¹æå–åè®®â€**ï¼Œåœ¨è„‘ä¸­è¯†åˆ«å‡º`Policy æ–‡æœ¬`ä¸­çš„æ‰€æœ‰åŸå­è¯­ä¹‰å•å…ƒã€‚
2.  **éªŒè¯æ˜ å°„**: å°†è¯†åˆ«å‡ºçš„æ¯ä¸ªè¯­ä¹‰ç‚¹ï¼Œé€ä¸€æ£€æŸ¥åœ¨`ODRLç­–ç•¥`ä¸­æ˜¯å¦æœ‰å¯¹åº”ä¸”è¯­ä¹‰ä¸€è‡´çš„è¡¨è¾¾ã€‚
3.  **é‡åŒ–ç»“æœ**: ç»Ÿè®¡æ€»è¯­ä¹‰ç‚¹æ•°é‡å’Œåœ¨ODRLä¸­è¢«æ­£ç¡®åæ˜ çš„æ•°é‡ï¼Œå¹¶åˆ—å‡ºæœªæ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹ã€‚

---
**è¯­ä¹‰ç‚¹æå–åè®® (Semantic Unit Extraction Protocol)**

**1. æ‰«æé”šç‚¹ (Scan Anchors):**
* **æˆæƒ/æ¥æ”¶å®ä½“**: å¿…é¡»ä¿ç•™å®Œæ•´çš„å®ä½“åç§° (ä¾‹å¦‚, "the Urban Planning Dept")ã€‚
* **åŠ¨ä½œåŠ¨è¯**: å¿…é¡»åŒ…å«æ‰€æœ‰ä¿®é¥°è¯å’Œå¦å®šè¯ (ä¾‹å¦‚, "securely process", "must not share")ã€‚
* **æ•°æ®èµ„äº§å¼•ç”¨**: å¿…é¡»åŒ…å«ç›¸å…³çš„æè¿°è¯ (ä¾‹å¦‚, "Traffic Data")ã€‚
* **æƒé™/ç¦æ­¢æ ‡è®°**: ä¾‹å¦‚, "grants", "prohibits"ã€‚
* **çº¦æŸé›†ç¾¤**: å¿…é¡»å°†æ—¶é—´ã€ç›®çš„ã€åœ°ç‚¹ã€æ•°é‡ç­‰çº¦æŸè§†ä¸ºä¸€ä¸ªä¸å¯åˆ†å‰²çš„æ•´ä½“ (ä¾‹å¦‚, "until 2025-12-31", "except PII data")ã€‚
* **ä¹‰åŠ¡çŸ­è¯­**: ä¾‹å¦‚, "must report", "is required to"ã€‚

**2. æå–è§„åˆ™ (Extraction Rules):**
* **âœ“ å¿ å®æ€§ (Fidelity)**: æå–æ—¶å¿…é¡»ä¿æŒåŸå§‹æ–‡æœ¬çš„ç¡®åˆ‡æªè¾ã€é¡ºåºå’Œå¤§å°å†™ã€‚
* **âœ“ å®Œæ•´æ€§ (Completeness)**: å¿…é¡»æ•è·å®Œæ•´çš„çŸ­è¯­ (ä¾‹å¦‚, å®Œæ•´çš„æ—¥æœŸ "2025-12-31")ã€‚
* **âœ“ å¤åˆå•å…ƒ (Compound Units)**: å¿…é¡»ä¿æŒé€»è¾‘å•å…ƒçš„å®Œæ•´æ€§ (ä¾‹å¦‚, "must not process externally" åº”è¢«è§†ä¸ºä¸€ä¸ªå•å…ƒ)ã€‚
* **âœ— æ’é™¤é¡¹ (Exclusion)**: å¿…é¡»å¿½ç•¥ç‹¬ç«‹çš„ã€æ— å®é™…è¯­ä¹‰çš„è¯­æ³•è¿æ¥è¯ (å¦‚ that, which, a, the ç­‰)ã€‚

**3. éªŒè¯ç¤ºä¾‹ (Validation Examples):**
* **âœ“ æœ‰æ•ˆè¯†åˆ«**
    * **æ–‡æœ¬**: "The Data Hub grants the Urban Planning Dept access to Traffic Data until 2025-12-31"
    * **åº”è¯†åˆ«çš„è¯­ä¹‰ç‚¹**: `["The Data Hub", "grants", "the Urban Planning Dept", "access", "Traffic Data", "until 2025-12-31"]`
* **âœ— æ— æ•ˆè¯†åˆ«**
    * **æ–‡æœ¬**: "Analytics teams may process sales records except PII data"
    * **é”™è¯¯è¯†åˆ«**: `["Analytics", "may process", "sales records", "except", "PII data"]`
    * **æ­£ç¡®è¯†åˆ«**: `["Analytics teams", "may process", "sales records", "except PII data"]` (åŸå› : "except PII data" æ˜¯ä¸€ä¸ªä¸å¯åˆ†å‰²çš„çº¦æŸå•å…ƒ)ã€‚
---

**è¯„ä¼°æ ‡å‡†ï¼š**
* **æ­£ç¡®åæ˜ **: ODRLä¸­æœ‰ç›´æ¥å¯¹åº”å…ƒç´ ä¸”è¯­ä¹‰å®Œå…¨åŒ¹é…ã€‚
* **æœªæ­£ç¡®åæ˜ **: ODRLä¸­ç¼ºå¤±å¯¹åº”å…ƒç´ ã€å…ƒç´ è¯­ä¹‰ä¸åŒ¹é…æˆ–ä¸å®Œæ•´ã€‚

**è¾“å‡ºè¦æ±‚ï¼š**
è¯·ä¸¥æ ¼æŒ‰ç…§`SemanticEvaluation`æ ¼å¼è¿”å›ç»“æœï¼ŒåŒ…å«ï¼š
1.  `total_semantic_units`: æ ¹æ®ä¸Šè¿°åè®®è¯†åˆ«å‡ºçš„è¯­ä¹‰ç‚¹æ€»æ•°ã€‚
2.  `correctly_reflected_units`: åœ¨ODRLä¸­è¢«æ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹æ•°é‡ã€‚
3.  `missing_or_incorrect_units`: æœªè¢«æ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹æè¿°åˆ—è¡¨ã€‚
**æ³¨æ„ï¼š`total_semantic_units` å¿…é¡»ç­‰äº `correctly_reflected_units` ä¸ `missing_or_incorrect_units` åˆ—è¡¨é•¿åº¦ä¹‹å’Œã€‚**
"""),
    ("human",
    """
è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯è¿›è¡Œè¯­ä¹‰è¯„ä¼°ï¼š

Policy æ–‡æœ¬:
```{policy_text}```

ODRL ç­–ç•¥ (JSON-LD æ ¼å¼):
```{odrl_policy_str}```
""")
])


# --- LangGraph å·¥ä½œæµçŠ¶æ€å®šä¹‰ ---
class EvaluationState(TypedDict):
    """å®šä¹‰å·¥ä½œæµä¸­ä¼ é€’çš„çŠ¶æ€"""
    mongo_uri: str
    db_name: str
    collection_name: str
    documents: List[Dict]
    structured_llm: Any
    processed_results: List[Dict]
    final_aggregated_results: Dict


# --- LangGraph èŠ‚ç‚¹å‡½æ•° ---

def initialize_llm_client():
    """åˆå§‹åŒ–LLMå’Œç»“æ„åŒ–è¾“å‡ºé“¾"""
    try:
        with open(API_KEY_PATH, "r", encoding='utf-8') as f:
            api_key = f.read().strip()
    except FileNotFoundError:
        raise ValueError(f"é”™è¯¯ï¼šç¯å¢ƒå˜é‡ 'OPENAI_API_KEY' æœªè®¾ç½®ï¼Œä¹Ÿæœªåœ¨ {API_KEY_PATH} æ‰¾åˆ°æ–‡ä»¶ã€‚")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­æä¾› API_KEY_PATH")

    llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.1, api_key=api_key, base_url="https://zzzzapi.com/v1")
    return llm.with_structured_output(SemanticEvaluation)

async def initialize_and_fetch_data(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹1: åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼Œå¹¶ä»æ•°æ®åº“è·å–æ•°æ®"""
    print("--- èŠ‚ç‚¹: åˆå§‹åŒ– & è·å–æ•°æ® ---")
    state['structured_llm'] = initialize_llm_client()

    db_manager = MongoDBManager(mongo_uri=state['mongo_uri'], mongo_db_name=state['db_name'])

    # å®šä¹‰æŠ•å½±ä»¥ä»…è·å–æ‰€éœ€å­—æ®µï¼Œæé«˜æ•ˆç‡
    projection_fields = {
        "usecase_key": 1,
        "policies.type": 1,
        "policies.text": 1,
        "policies.reflection_attempts_validation": 1,
    }
    for odrl_field in ODRL_STRATEGIES.values():
        projection_fields[f"policies.{odrl_field}"] = 1

    state['documents'] = await db_manager.fetch_all_rules(
        collection_name=state['collection_name'],
        projection=projection_fields
    )

    if not state['documents']:
        raise ValueError(f"ä»é›†åˆ '{state['collection_name']}' æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£ã€‚è¯·æ£€æŸ¥æ•°æ®åº“å’Œé›†åˆåç§°ã€‚")

    print(f"æˆåŠŸè·å– {len(state['documents'])} ä»½ usecase æ–‡æ¡£ã€‚")
    # å¯¹äºè„šæœ¬ç±»åº”ç”¨ï¼Œé€šå¸¸ä¸éœ€è¦æ˜¾å¼å…³é—­è¿æ¥
    # await db_manager.close_connection()
    return state

async def run_syntax_validation_async(odrl_content: Dict, shacl_path: str, total_constraints: int) -> float:
    """
    åœ¨ç‹¬ç«‹çš„çº¿ç¨‹ä¸­å¼‚æ­¥æ‰§è¡ŒCPUå¯†é›†çš„SHACLéªŒè¯ï¼Œå¹¶åº”ç”¨å¹¶å‘æ§åˆ¶ã€‚
    """
    async with cpu_semaphore:
        try:
            # asyncio.to_thread å°†åŒæ­¥å‡½æ•°æ”¾åˆ°ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œï¼Œé˜²æ­¢é˜»å¡
            # validate_odrl_against_shacl æ˜¯ä¸€ä¸ªåŒæ­¥å‡½æ•°
            _, _, num_violations, _ = await asyncio.to_thread(
                validate_odrl_against_shacl, odrl_content, shacl_path
            )
            score = (total_constraints - num_violations) / total_constraints
            return max(0, score)
        except Exception as e:
            print(f"è¯­æ³•éªŒè¯å¤±è´¥ï¼Œå°†è¿”å› 0.0 åˆ†ã€‚é”™è¯¯: {e}")
            return 0.0

async def run_semantic_evaluation_async(structured_llm, policy_text: str, odrl_policy_str: str) -> float:
    """
    ä½¿ç”¨LLMè®¡ç®—å•æ¬¡è¯­ä¹‰å¾—åˆ†ï¼ˆå·²æ·»åŠ å¹¶å‘æ§åˆ¶ï¼‰ã€‚
    """
    async with io_semaphore:
        chain = SEMANTIC_PROMPT | structured_llm
        try:
            result: SemanticEvaluation = await chain.ainvoke({
                "policy_text": policy_text,
                "odrl_policy_str": odrl_policy_str
            })
            return result.correctly_reflected_units / result.total_semantic_units if result.total_semantic_units > 0 else 0.0
        except Exception as e:
            print(f"LLM è¯­ä¹‰è¯„ä¼°å¤±è´¥ï¼Œå°†è¿”å› 0.0 åˆ†ã€‚é”™è¯¯: {e}")
            return 0.0

async def evaluate_single_policy(policy: Dict, structured_llm: Any) -> Dict:
    """
    å¯¹å•ä¸ªpolicyçš„æ‰€æœ‰ç­–ç•¥è¿›è¡Œå¹¶è¡Œçš„è¯­æ³•å’Œè¯­ä¹‰è¯„ä¼°ã€‚
    æ–°å¢ï¼šæ£€æŸ¥æ— æ•ˆçš„ODRLï¼ˆå¦‚åŒ…å«é”™è¯¯ä¿¡æ¯ï¼‰ï¼Œå¹¶ç›´æ¥å°†å¾—åˆ†è®°ä¸º0ã€‚
    """
    policy_scores = {"syntactic": {}, "semantic": {}}
    syntax_tasks = {}
    semantic_tasks = {}

    # 1. ä¸ºæ‰€æœ‰éœ€è¦è®¡ç®—çš„ä»»åŠ¡åˆ›å»ºåç¨‹
    odrl_type = policy.get("type")
    if odrl_type in TOTAL_CONSTRAINTS_BY_TYPE:
        total_constraints = TOTAL_CONSTRAINTS_BY_TYPE[odrl_type]
        shacl_path = SHACL_PATHS[odrl_type]

        for strategy_name, odrl_field in ODRL_STRATEGIES.items():
            odrl_content = policy.get(odrl_field)

            # --- æ–°å¢çš„æ ¸å¿ƒæ£€æŸ¥é€»è¾‘ ---
            # å¦‚æœ ODRL å†…å®¹ä¸ºç©ºï¼Œæˆ–æ˜¯ä¸€ä¸ªé”™è¯¯å­—å…¸ï¼Œåˆ™æ ‡è®°ä¸ºæ— æ•ˆ
            is_invalid = not odrl_content or (isinstance(odrl_content, dict) and "error" in odrl_content)

            if is_invalid:
                # å½“ ODRL æ— æ•ˆæ—¶ï¼Œä¸ºå…¶åˆ›å»ºè¿”å› 0 çš„ "ä¼ªä»»åŠ¡"
                # è¿™æ ·å¯ä»¥ä¿æŒåç»­ gather å’Œç»“æœè§£æé€»è¾‘çš„ç»Ÿä¸€æ€§
                if odrl_content:  # ä»…åœ¨æœ‰é”™è¯¯å†…å®¹æ—¶æ‰“å°æ—¥å¿—ï¼Œå¯¹äºå®Œå…¨ä¸ºç©ºçš„ä¸æ‰“å°
                    print(f"æ£€æµ‹åˆ°æ— æ•ˆ ODRL [Policy Text: '{policy.get('text', '')[:30]}...', Strategy: {strategy_name}]. å¾—åˆ†è®°ä¸º 0ã€‚")
                
                syntax_tasks[strategy_name] = return_zero()
                semantic_tasks[strategy_name] = [return_zero() for _ in range(LLM_JUDGE_COUNT)]
            
            else:
                # ODRL å†…å®¹æœ‰æ•ˆï¼ŒæŒ‰åŸé€»è¾‘åˆ›å»ºè¯„ä¼°ä»»åŠ¡
                # åˆ›å»ºè¯­æ³•ä»»åŠ¡
                syntax_tasks[strategy_name] = run_syntax_validation_async(
                    odrl_content, shacl_path, total_constraints
                )

                # åˆ›å»ºè¯­ä¹‰ä»»åŠ¡ï¼ˆæ¯ä¸ªè£åˆ¤ä¸€ä¸ªï¼‰
                odrl_str = json.dumps(odrl_content)
                semantic_tasks[strategy_name] = [
                    run_semantic_evaluation_async(structured_llm, policy["text"], odrl_str)
                    for _ in range(LLM_JUDGE_COUNT)
                ]

    # --- åç»­é€»è¾‘ä¿æŒä¸å˜ ---

    # 2. å¹¶å‘æ‰§è¡Œæ‰€æœ‰å·²åˆ›å»ºçš„ä»»åŠ¡
    all_tasks_to_run = list(syntax_tasks.values())
    for judge_tasks in semantic_tasks.values():
        all_tasks_to_run.extend(judge_tasks)

    # å¦‚æœæ²¡æœ‰ä»»ä½•ä»»åŠ¡ï¼Œç›´æ¥è¿”å›
    if not all_tasks_to_run:
        return policy_scores

    # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    all_results = await asyncio.gather(*all_tasks_to_run)

    # 3. è§£æç»“æœ
    result_index = 0
    # è§£æè¯­æ³•å¾—åˆ†
    for strategy_name in syntax_tasks.keys():
        policy_scores["syntactic"][strategy_name] = all_results[result_index]
        result_index += 1

    # è§£æè¯­ä¹‰å¾—åˆ†
    for strategy_name, judge_tasks in semantic_tasks.items():
        if not judge_tasks:
            continue

        # æå–å±äºå½“å‰ç­–ç•¥çš„è¯­ä¹‰å¾—åˆ†ç»“æœ
        judge_scores = all_results[result_index : result_index + len(judge_tasks)]
        result_index += len(judge_tasks)

        # è®¡ç®—å¹³å‡åˆ†
        if judge_scores:
            policy_scores["semantic"][strategy_name] = sum(judge_scores) / len(judge_scores)

    return policy_scores

async def evaluate_policies(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹2: å¹¶è¡Œè¯„ä¼°æ‰€æœ‰ policies çš„è¯­æ³•å’Œè¯­ä¹‰å¾—åˆ†"""
    print(f"\n--- èŠ‚ç‚¹: è¯„ä¼° Policies (å…± {len(state['documents'])} ä¸ª Usecases) ---")
    tasks = [evaluate_single_policy(policy, state['structured_llm']) for doc in state['documents'] for policy in doc.get("policies", [])]
    all_policy_scores = await asyncio.gather(*tasks)

    processed_results = []
    policy_counter = 0
    for doc in state['documents']:
        usecase_key = doc['usecase_key']
        category = "unknown"
        if usecase_key.startswith("su_"): category = "simple"
        elif usecase_key.startswith("cu_j_"): category = "concurrent"
        elif usecase_key.startswith("cu_p_"): category = "progressive"

        for policy in doc.get("policies", []):
            processed_results.append({
                "usecase_key": usecase_key, "category": category,
                "reflection_attempts": policy.get("reflection_attempts_validation", 0),
                "scores": all_policy_scores[policy_counter]
            })
            policy_counter += 1

    state['processed_results'] = processed_results
    print(f"è¯„ä¼°å®Œæˆï¼Œå…±å¤„ç† {len(processed_results)} ä¸ª policiesã€‚")
    return state

def aggregate_and_save_results(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹3: èšåˆæ‰€æœ‰å¾—åˆ†å¹¶ä¿å­˜åˆ°æ–‡ä»¶"""
    print("\n--- èŠ‚ç‚¹: èšåˆç»“æœ & ä¿å­˜æ–‡ä»¶ ---")
    # æŒ‰ usecase_key -> category èšåˆ
    usecase_level_data = defaultdict(lambda: {"category": "", "reflection_attempts": [], "syntactic": defaultdict(list), "semantic": defaultdict(list)})
    for res in state['processed_results']:
        key = res['usecase_key']
        usecase_level_data[key]['category'] = res['category']
        usecase_level_data[key]['reflection_attempts'].append(res['reflection_attempts'])
        for s_name, score in res['scores']['syntactic'].items(): usecase_level_data[key]['syntactic'][s_name].append(score)
        for s_name, score in res['scores']['semantic'].items(): usecase_level_data[key]['semantic'][s_name].append(score)

    usecase_averages = {key: {"category": data['category'],
        "avg_reflection": sum(data['reflection_attempts']) / len(data['reflection_attempts']) if data['reflection_attempts'] else 0,
        "avg_syntactic": {s_name: sum(scores) / len(scores) for s_name, scores in data['syntactic'].items() if scores},
        "avg_semantic": {s_name: sum(scores) / len(scores) for s_name, scores in data['semantic'].items() if scores},
    } for key, data in usecase_level_data.items()}

    category_level_data = defaultdict(lambda: {"reflection_attempts": [], "syntactic": defaultdict(list), "semantic": defaultdict(list)})
    for key, avg_data in usecase_averages.items():
        for category in [avg_data['category'], 'all']: # åŒæ—¶å¡«å……ç‰¹å®šåˆ†ç±»å’Œ'all'åˆ†ç±»
            category_level_data[category]['reflection_attempts'].append(avg_data['avg_reflection'])
            for s_name, score in avg_data['avg_syntactic'].items(): category_level_data[category]['syntactic'][s_name].append(score)
            for s_name, score in avg_data['avg_semantic'].items(): category_level_data[category]['semantic'][s_name].append(score)

    final_results = {}
    for category, data in category_level_data.items():
        final_results[category] = {"average_reflection_attempts": sum(data['reflection_attempts']) / len(data['reflection_attempts']) if data['reflection_attempts'] else 0, "performance_by_strategy": {}}
        for s_name in ODRL_STRATEGIES.keys():
            syn_scores, sem_scores = data['syntactic'][s_name], data['semantic'][s_name]
            final_results[category]["performance_by_strategy"][s_name] = {
                "syntactic_score": f"{sum(syn_scores) / len(syn_scores):.2%}" if syn_scores else "N/A",
                "semantic_score": f"{sum(sem_scores) / len(sem_scores):.2%}" if sem_scores else "N/A",
            }

    output_data = {"metadata": {"source_database": state['db_name'], "source_collection": state['collection_name']}, "results": final_results}

    with open(OUTPUT_RESULTS_PATH, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=4, ensure_ascii=False)

    print(f"èšåˆå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {OUTPUT_RESULTS_PATH}")
    state['final_aggregated_results'] = output_data
    return state

# --- æ„å»º LangGraph å·¥ä½œæµ ---
workflow = StateGraph(EvaluationState)
workflow.add_node("initialize_and_fetch", initialize_and_fetch_data)
workflow.add_node("evaluate_policies", evaluate_policies)
workflow.add_node("aggregate_and_save", aggregate_and_save_results)
workflow.set_entry_point("initialize_and_fetch")
workflow.add_edge("initialize_and_fetch", "evaluate_policies")
workflow.add_edge("evaluate_policies", "aggregate_and_save")
workflow.add_edge("aggregate_and_save", END)
app = workflow.compile()

# --- ä¸»æ‰§è¡Œå‡½æ•° ---
async def main():
    initial_state = {"mongo_uri": MONGO_URI, "db_name": MONGO_DB_NAME, "collection_name": COLLECTION_NAME}
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ LangGraph å·¥ä½œæµ...")
    final_state = await app.ainvoke(initial_state)
    print("\nâœ… å·¥ä½œæµæ‰§è¡Œå®Œæ¯•ã€‚")
    print("\n--- æœ€ç»ˆè¯„ä¼°ç»“æœ ---")
    print(json.dumps(final_state.get('final_aggregated_results', {}), indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())