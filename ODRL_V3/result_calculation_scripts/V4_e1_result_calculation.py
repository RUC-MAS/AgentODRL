import asyncio
import json
import os
from pathlib import Path
from typing import List, Dict, TypedDict, Any
from collections import defaultdict

# --- Langchain & LangGraph æ ¸å¿ƒç»„ä»¶ ---
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END

# --- å¯¼å…¥æ‚¨çš„çœŸå®æ¨¡å— ---
from mongodb import MongoDBManager
from ODRL_Check import validate_odrl_against_shacl

# --- ç”¨æˆ·éœ€è¦é…ç½®çš„å¸¸é‡ ---

# MongoDB é…ç½®
MONGO_URI = "mongodb://localhost:27017/"
MONGO_DB_NAME = "odrl3_final"
COLLECTION_NAME = "e1_41nano_2"

# OpenAI API Key (è¯·ç¡®ä¿ç¯å¢ƒå˜é‡ OPENAI_API_KEY å·²è®¾ç½®)
# æˆ–è€…å–æ¶ˆä¸‹ä¸€è¡Œæ³¨é‡Šå¹¶æä¾›æ–‡ä»¶è·¯å¾„
API_KEY_PATH = r"C:\Users\34085\Desktop\Agent\ALL_API_KEY1.txt"

# SHACL æ–‡ä»¶è·¯å¾„ (çœŸå®è·¯å¾„)
SHACL_PATHS = {
    "set": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Rule_Shapes.ttl",
    "offer": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Offer_Shape.ttl",
    "agreement": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Agreement_Shape.ttl",
}

# ODRL ç±»å‹å¯¹åº”çš„æ€»çº¦æŸæ•°é‡
TOTAL_CONSTRAINTS_BY_TYPE = {
    "set": 29,
    "offer": 23,
    "agreement": 24,
}

# ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„
OUTPUT_RESULTS_PATH = Path(r"ODRL_V3\result\3e\e1\e1_41nano_V4_2.json")

# å®šä¹‰éœ€è¦è¯„ä¼°çš„ ODRL ç­–ç•¥å­—æ®µå (ä¸Mongoæ–‡æ¡£å­—æ®µå®Œå…¨å¯¹åº”)
ODRL_STRATEGIES = {
    "ontology": 'initial_odrl',
    "vldb": 'final_odrl_branch_A_constraint',
    "vldb_semantic": 'enhanced_odrl_after_constraint',
    "semantic_syntactic": 'final_odrl_branch_B_validation'
}

# æ–°å¢ï¼šå…¨å±€æœ€å¤§å¹¶å‘æ•°é‡æ§åˆ¶
# I/Oå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚APIè°ƒç”¨ï¼‰çš„å¹¶å‘é™åˆ¶
MAX_IO_CONCURRENCY = 50
io_semaphore = asyncio.Semaphore(MAX_IO_CONCURRENCY)

# CPUå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚SHACLéªŒè¯ï¼‰çš„å¹¶å‘é™åˆ¶
# é€šå¸¸è®¾ç½®ä¸ºæœºå™¨çš„CPUæ ¸å¿ƒæ•°
MAX_CPU_CONCURRENCY = 20
cpu_semaphore = asyncio.Semaphore(MAX_CPU_CONCURRENCY)

async def return_zero() -> float:
    """ä¸€ä¸ªç®€å•çš„å¼‚æ­¥å‡½æ•°ï¼Œç”¨äºåœ¨æ£€æµ‹åˆ°æ— æ•ˆODRLæ—¶è¿”å›0.0åˆ†ã€‚"""
    return 0.0

# --- Pydantic æ¨¡å‹å®šä¹‰ ---
# 1. ä¸º "è£åˆ¤1 (è¯†åˆ«å™¨)" è®¾è®¡çš„æ–°æ¨¡å‹
class SemanticPointIdentification(BaseModel):
    """ç”¨äºè§„èŒƒâ€œè£åˆ¤1â€è¾“å‡ºçš„æ•°æ®ç»“æ„ã€‚"""
    semantic_points: List[str] = Field(
        ...,
        description="ä»Policyæ–‡æœ¬ä¸­ä¸¥æ ¼æŒ‰ç…§â€œè¯­ä¹‰ç‚¹æå–åè®®â€æå–å‡ºçš„ã€æ‰€æœ‰ç‹¬ç«‹çš„åŸå­è¯­ä¹‰ç‚¹åˆ—è¡¨ã€‚"
    )

# --- æ–°å¢: "è£åˆ¤2" çš„ç²¾ç»†åŒ–è¯„ä¼°æ¨¡å‹ ---
from enum import Enum  # <-- æ–°å¢æ­¤è¡Œ

# --- æ–°å¢: "è£åˆ¤2" çš„ç²¾ç»†åŒ–è¯„ä¼°æ¨¡å‹ ---
class EvaluationCategory(str, Enum):
    """å®šä¹‰è¯­ä¹‰è¯„ä¼°çš„å››ä¸ªç­‰çº§"""
    PERFECTLY_MATCHED = "PERFECTLY_MATCHED"
    PARTIALLY_MATCHED = "PARTIALLY_MATCHED"
    MISMATCHED = "MISMATCHED"
    MISSING = "MISSING"

class DetailedSemanticUnit(BaseModel):
    """å¯¹å•ä¸ªè¯­ä¹‰ç‚¹çš„è¯¦ç»†è¯„ä¼°"""
    semantic_point_text: str = Field(..., description="ä»Policyæ–‡æœ¬ä¸­æå–çš„åŸå§‹è¯­ä¹‰ç‚¹ã€‚")
    evaluation: EvaluationCategory = Field(..., description="è¯¥è¯­ä¹‰ç‚¹åœ¨ODRLä¸­çš„åŒ¹é…ç¨‹åº¦è¯„ä¼°ã€‚")
    justification: str = Field(..., description="å¯¹å½“å‰è¯„ä¼°ç­‰çº§çš„ç®€è¦è§£é‡Šã€‚")

class FineGrainedSemanticEvaluation(BaseModel):
    """ç”¨äºè§„èŒƒ"è£åˆ¤2"è¾“å‡ºçš„ç²¾ç»†åŒ–è¯­ä¹‰è¯„ä¼°ç»“æœçš„æ•°æ®ç»“æ„"""
    evaluated_units: List[DetailedSemanticUnit] = Field(
        ...,
        description="å¯¹ä»è£åˆ¤1æä¾›çš„æ¸…å•ä¸­çš„æ¯ä¸€ä¸ªè¯­ä¹‰ç‚¹è¿›è¡Œçš„è¯¦ç»†è¯„ä¼°åˆ—è¡¨ã€‚"
    )
    hallucinated_elements: List[str] = Field(
        default=[],
        description="åœ¨ODRLä¸­å­˜åœ¨ï¼Œä½†æ— æ³•åœ¨åŸå§‹Policyæ–‡æœ¬ä¸­æ‰¾åˆ°å¯¹åº”ä¾æ®çš„å…ƒç´ æè¿°åˆ—è¡¨ï¼ˆå¹»è§‰å†…å®¹ï¼‰ã€‚"
    )

# --- Prompt å®šä¹‰ (å¤ç”¨è‡ªåŸä»£ç ) ---
IDENTIFICATION_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
"""
æ‚¨æ˜¯ä¸€ä½ç²¾é€šODRLå’Œè‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸“å®¶ã€‚æ‚¨çš„ä»»åŠ¡æ˜¯ç²¾ç¡®è¯„ä¼°ç»™å®šçš„ODRLç­–ç•¥æ˜¯å¦å‡†ç¡®åæ˜ äº†åŸå§‹Policyæ–‡æœ¬ä¸­çš„æ‰€æœ‰è¯­ä¹‰ç‚¹ã€‚

**æ ¸å¿ƒä»»åŠ¡ï¼š**
1.  **è¯†åˆ«è¯­ä¹‰ç‚¹**: ä¸¥æ ¼éµå¾ªä¸‹è¿°çš„ **â€œè¯­ä¹‰ç‚¹æå–åè®®â€**ï¼Œåœ¨è„‘ä¸­è¯†åˆ«å‡º`Policy æ–‡æœ¬`ä¸­çš„æ‰€æœ‰åŸå­è¯­ä¹‰å•å…ƒã€‚
2.  **éªŒè¯æ˜ å°„**: å°†è¯†åˆ«å‡ºçš„æ¯ä¸ªè¯­ä¹‰ç‚¹ï¼Œé€ä¸€æ£€æŸ¥åœ¨`ODRLç­–ç•¥`ä¸­æ˜¯å¦æœ‰å¯¹åº”ä¸”è¯­ä¹‰ä¸€è‡´çš„è¡¨è¾¾ã€‚
3.  **é‡åŒ–ç»“æœ**: ç»Ÿè®¡æ€»è¯­ä¹‰ç‚¹æ•°é‡å’Œåœ¨ODRLä¸­è¢«æ­£ç¡®åæ˜ çš„æ•°é‡ï¼Œå¹¶åˆ—å‡ºæœªæ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹ã€‚

---
**è¯­ä¹‰ç‚¹æå–åè®® (Semantic Unit Extraction Protocol)**

**1. æ‰«æé”šç‚¹ (Scan Anchors):**
* **æˆæƒ/æ¥æ”¶å®ä½“**: å¿…é¡»ä¿ç•™å®Œæ•´çš„å®ä½“åç§° (ä¾‹å¦‚, "the Urban Planning Dept")ã€‚
* **åŠ¨ä½œåŠ¨è¯**: å¿…é¡»åŒ…å«æ‰€æœ‰ä¿®é¥°è¯å’Œå¦å®šè¯ (ä¾‹å¦‚, "securely process", "must not share")ã€‚
* **æ•°æ®èµ„äº§å¼•ç”¨**: å¿…é¡»åŒ…å«ç›¸å…³çš„æè¿°è¯ (ä¾‹å¦‚, "Traffic Data")ã€‚
* **æƒé™/ç¦æ­¢æ ‡è®°**: ä¾‹å¦‚, "grants", "prohibits"ã€‚
* **çº¦æŸé›†ç¾¤**: å¿…é¡»å°†æ—¶é—´ã€ç›®çš„ã€åœ°ç‚¹ã€æ•°é‡ç­‰çº¦æŸè§†ä¸ºä¸€ä¸ªä¸å¯åˆ†å‰²çš„æ•´ä½“ (ä¾‹å¦‚, "until 2025-12-31", "except PII data")ã€‚
* **ä¹‰åŠ¡çŸ­è¯­**: ä¾‹å¦‚, "must report", "is required to"ã€‚

**2. æå–è§„åˆ™ (Extraction Rules):**
* **âœ“ å¿ å®æ€§ (Fidelity)**: æå–æ—¶å¿…é¡»ä¿æŒåŸå§‹æ–‡æœ¬çš„ç¡®åˆ‡æªè¾ã€é¡ºåºå’Œå¤§å°å†™ã€‚
* **âœ“ å®Œæ•´æ€§ (Completeness)**: å¿…é¡»æ•è·å®Œæ•´çš„çŸ­è¯­ (ä¾‹å¦‚, å®Œæ•´çš„æ—¥æœŸ "2025-12-31")ã€‚
* **âœ“ å¤åˆå•å…ƒ (Compound Units)**: å¿…é¡»ä¿æŒé€»è¾‘å•å…ƒçš„å®Œæ•´æ€§ (ä¾‹å¦‚, "must not process externally" åº”è¢«è§†ä¸ºä¸€ä¸ªå•å…ƒ)ã€‚
* **âœ— æ’é™¤é¡¹ (Exclusion)**: å¿…é¡»å¿½ç•¥ç‹¬ç«‹çš„ã€æ— å®é™…è¯­ä¹‰çš„è¯­æ³•è¿æ¥è¯ (å¦‚ that, which, a, the ç­‰)ã€‚

**3. éªŒè¯ç¤ºä¾‹ (Validation Examples):**
* **âœ“ æœ‰æ•ˆè¯†åˆ«**
    * **æ–‡æœ¬**: "The Data Hub grants the Urban Planning Dept access to Traffic Data until 2025-12-31"
    * **åº”è¯†åˆ«çš„è¯­ä¹‰ç‚¹**: `["The Data Hub", "grants", "the Urban Planning Dept", "access", "Traffic Data", "until 2025-12-31"]`
* **âœ— æ— æ•ˆè¯†åˆ«**
    * **æ–‡æœ¬**: "Analytics teams may process sales records except PII data"
    * **é”™è¯¯è¯†åˆ«**: `["Analytics", "may process", "sales records", "except", "PII data"]`
    * **æ­£ç¡®è¯†åˆ«**: `["Analytics teams", "may process", "sales records", "except PII data"]` (åŸå› : "except PII data" æ˜¯ä¸€ä¸ªä¸å¯åˆ†å‰²çš„çº¦æŸå•å…ƒ)ã€‚
---
**4. è¾“å‡ºè¦æ±‚:**
æ‚¨çš„è¾“å‡ºå¿…é¡»ä¸¥æ ¼ç¬¦åˆ `SemanticPointIdentification` æ ¼å¼ï¼Œåªè¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰è¯­ä¹‰ç‚¹å­—ç¬¦ä¸²çš„ `semantic_points` åˆ—è¡¨ã€‚ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–è¯„ä¼°ã€‚
"""),
    ("human",
    """
è¯·æ ¹æ®â€œè¯­ä¹‰ç‚¹æå–åè®®â€å¤„ç†ä»¥ä¸‹æ–‡æœ¬ï¼š

Policy æ–‡æœ¬:
```{policy_text}```
""")
])

EVALUATION_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
"""
æ‚¨æ˜¯ä¸€ä½æå…¶ä¸¥è‹›å’Œç²¾å‡†çš„ODRLåˆ†æä¸“å®¶ï¼Œæ‹…ä»»â€œè£åˆ¤2â€çš„è§’è‰²ã€‚

---
**æ ¸å¿ƒä»»åŠ¡ä¸è¯„åˆ†åè®® (Fine-Grained Scoring Protocol)**

**1. è¯„ä¼°èŒƒå›´:**
æ‚¨çš„å”¯ä¸€ä»»åŠ¡æ˜¯ä¸¥æ ¼æŒ‰ç…§ä¸‹æ–¹æä¾›çš„`è¯­ä¹‰ç‚¹æ¸…å•`ï¼Œé€é¡¹è¯„ä¼°è¯¥æ¸…å•ä¸­çš„æ¯ä¸€ä¸ªç‚¹åœ¨ODRLç­–ç•¥ä¸­çš„åæ˜ æƒ…å†µã€‚`Policy æ–‡æœ¬`ä»…ä¾›æ‚¨åœ¨è¯„ä¼°æ—¶ç†è§£ä¸Šä¸‹æ–‡ï¼Œä½†æ‚¨è¯„ä¼°çš„èŒƒå›´ã€å¿…é¡»ã€‘ä¸¥æ ¼é™å®šåœ¨ç»™å®šçš„æ¸…å•å†…ã€‚

**2. é€ç‚¹è¯„ä¼°:**
å¯¹æ¸…å•ä¸­çš„æ¯ä¸€ä¸ªè¯­ä¹‰ç‚¹ï¼Œæ‚¨å¿…é¡»æ ¹æ®ä»¥ä¸‹å››ä¸ªç­‰çº§è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºç†ç”±ï¼š

* **PERFECTLY_MATCHED (å¾—åˆ†: 1.0):** ODRLä¸­çš„è¡¨è¿°å®Œå…¨ã€å‡†ç¡®ã€æ— æ­§ä¹‰åœ°åæ˜ äº†è¯¥è¯­ä¹‰ç‚¹çš„æ‰€æœ‰ä¿¡æ¯ã€‚
    * *ç¤ºä¾‹*: æ–‡æœ¬ "until 2025-12-31" å¯¹åº” ODRL `<odrl:constraint><odrl:rightOperand rdf:datatype="http://www.w3.org/2001/XMLSchema#date">2025-12-31</odrl:rightOperand>...</odrl:constraint>`ã€‚

* **PARTIALLY_MATCHED (å¾—åˆ†: 0.5):** ODRLä¸­åæ˜ äº†è¯­ä¹‰ç‚¹çš„æ ¸å¿ƒæ€æƒ³ï¼Œä½†å­˜åœ¨ä¿¡æ¯ç¼ºå¤±æˆ–è½»å¾®ä¸å‡†ç¡®ã€‚
    * *ç¤ºä¾‹*: æ–‡æœ¬ "the Urban Planning Dept" å¯¹åº” ODRL `assignee: "Urban Dept"` (åç§°ä¸å®Œæ•´)ã€‚æ–‡æœ¬ "securely process" å¯¹åº” ODRL `action: "process"` (ç¼ºå°‘äº†â€œsecurelyâ€è¿™ä¸€ä¿®é¥°)ã€‚

* **MISMATCHED (å¾—åˆ†: 0.1):** ODRLä¸­æœ‰çœ‹ä¼¼å¯¹åº”çš„å…ƒç´ ï¼Œä½†å…¶é€»è¾‘æˆ–å«ä¹‰ä¸åŸæ–‡å®Œå…¨é”™è¯¯ã€‚
    * *ç¤ºä¾‹*: æ–‡æœ¬è¦æ±‚â€œå…è®¸(grants)â€ï¼ŒODRLä¸­å´ä½¿ç”¨äº†â€œç¦æ­¢(prohibits)â€ã€‚æ–‡æœ¬è¦æ±‚â€œç›®çš„ä¸ºç§‘ç ”â€ï¼ŒODRLä¸­å´å†™æˆâ€œç›®çš„ä¸ºå•†ä¸šâ€ã€‚

* **MISSING (å¾—åˆ†: 0.0):** ODRLä¸­å®Œå…¨æ²¡æœ‰èƒ½å¯¹åº”ä¸Šè¯¥è¯­ä¹‰ç‚¹çš„ä»»ä½•ä¿¡æ¯ã€‚

**3. å¹»è§‰å†…å®¹æ£€æŸ¥:**
åœ¨å®Œæˆæ¸…å•è¯„ä¼°åï¼Œæ£€æŸ¥ODRLä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•`Policy æ–‡æœ¬`ä¸­æœªæåŠçš„é™åˆ¶ã€æƒé™æˆ–å®ä½“ï¼ˆå³â€œå¹»è§‰â€å†…å®¹ï¼‰ã€‚

**4. è¾“å‡ºè¦æ±‚:**
æ‚¨å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ `FineGrainedSemanticEvaluation` æ ¼å¼è¾“å‡ºç»“æœã€‚
- `evaluated_units` åˆ—è¡¨çš„é•¿åº¦ã€å¿…é¡»ã€‘ä¸è¾“å…¥çš„ `è¯­ä¹‰ç‚¹æ¸…å•` çš„é•¿åº¦å®Œå…¨ä¸€è‡´ã€‚
- `hallucinated_elements` åˆ—è¡¨ç”¨äºè®°å½•æ‰€æœ‰å¹»è§‰å†…å®¹ã€‚
"""),
    ("human",
"""
è¯·æ ¹æ®â€œç²¾ç»†åŒ–è¯„åˆ†åè®®â€ï¼Œè¯„ä¼°ä»¥ä¸‹ ODRL ç­–ç•¥å¯¹â€œè¯­ä¹‰ç‚¹æ¸…å•â€çš„åæ˜ æƒ…å†µã€‚

Policy æ–‡æœ¬ (ä¾›å‚è€ƒ):
```{policy_text}```

è¯­ä¹‰ç‚¹æ¸…å• (å¿…é¡»ä¸¥æ ¼æŒ‰ç…§æ­¤æ¸…å•é€ä¸€è¯„ä¼°ï¼Œä¸è¦å¢åˆ ):
```{semantic_points_list}```

ODRL ç­–ç•¥ (JSON-LD æ ¼å¼):
```{odrl_policy_str}```
""")
])


# --- LangGraph å·¥ä½œæµçŠ¶æ€å®šä¹‰ ---
class EvaluationState(TypedDict):
    """å®šä¹‰å·¥ä½œæµä¸­ä¼ é€’çš„çŠ¶æ€"""
    mongo_uri: str
    db_name: str
    collection_name: str
    documents: List[Dict]
    # ä¿®æ”¹: 'structured_llm' -> 'llm_clients'
    llm_clients: Dict[str, Any] # å°†æŒæœ‰ 'holistic' å’Œ 'fine_grained' ä¸¤ä¸ªå®¢æˆ·ç«¯
    processed_results: List[Dict]
    final_aggregated_results: Dict



# --- LangGraph èŠ‚ç‚¹å‡½æ•° ---

def initialize_llm_clients():
    """åˆå§‹åŒ–LLMå’Œç»“æ„åŒ–è¾“å‡ºé“¾"""
    try:
        with open(API_KEY_PATH, "r", encoding='utf-8') as f:
            api_key = f.read().strip()
    except FileNotFoundError:
        raise ValueError(f"é”™è¯¯ï¼šç¯å¢ƒå˜é‡ 'OPENAI_API_KEY' æœªè®¾ç½®ï¼Œä¹Ÿæœªåœ¨ {API_KEY_PATH} æ‰¾åˆ°æ–‡ä»¶ã€‚")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­æä¾› API_KEY_PATH")

    llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.0, api_key=api_key, base_url="https://zzzzapi.com/v1")
    # è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ä¸¤ç§æ–°è§’è‰²çš„å®¢æˆ·ç«¯
    return {
        "identifier": llm.with_structured_output(SemanticPointIdentification),
        "evaluator": llm.with_structured_output(FineGrainedSemanticEvaluation)
    }

async def initialize_and_fetch_data(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹1: åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼Œå¹¶ä»æ•°æ®åº“è·å–æ•°æ®"""
    print("--- èŠ‚ç‚¹: åˆå§‹åŒ– & è·å–æ•°æ® ---")
    
    # æ ¸å¿ƒä¿®æ­£: ç¡®ä¿è°ƒç”¨æ–°çš„åˆå§‹åŒ–å‡½æ•°ï¼Œå¹¶å°†ç»“æœå­˜å…¥ 'llm_clients' é”®
    state['llm_clients'] = initialize_llm_clients()

    db_manager = MongoDBManager(mongo_uri=state['mongo_uri'], mongo_db_name=state['db_name'])

    # å®šä¹‰æŠ•å½±ä»¥ä»…è·å–æ‰€éœ€å­—æ®µï¼Œæé«˜æ•ˆç‡
    projection_fields = {
        "usecase_key": 1,
        "usecase_text": 1,          # <-- æ–°å¢
        # "rewritten_usecase": 1,     # <-- æ–°å¢
        "policies.type": 1,
        "policies.text": 1,
        "policies.reflection_attempts_validation": 1,
    }
    for odrl_field in ODRL_STRATEGIES.values():
        projection_fields[f"policies.{odrl_field}"] = 1

    state['documents'] = await db_manager.fetch_all_rules(
        collection_name=state['collection_name'],
        projection=projection_fields
    )

    if not state['documents']:
        raise ValueError(f"ä»é›†åˆ '{state['collection_name']}' æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£ã€‚è¯·æ£€æŸ¥æ•°æ®åº“å’Œé›†åˆåç§°ã€‚")

    print(f"æˆåŠŸè·å– {len(state['documents'])} ä»½ usecase æ–‡æ¡£ã€‚")
    return state

async def run_syntax_validation_async(odrl_content: Dict, shacl_path: str, total_constraints: int) -> float:
    """
    åœ¨ç‹¬ç«‹çš„çº¿ç¨‹ä¸­å¼‚æ­¥æ‰§è¡ŒCPUå¯†é›†çš„SHACLéªŒè¯ï¼Œå¹¶åº”ç”¨å¹¶å‘æ§åˆ¶ã€‚
    """
    async with cpu_semaphore:
        try:
            # asyncio.to_thread å°†åŒæ­¥å‡½æ•°æ”¾åˆ°ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œï¼Œé˜²æ­¢é˜»å¡
            # validate_odrl_against_shacl æ˜¯ä¸€ä¸ªåŒæ­¥å‡½æ•°
            _, _, num_violations, _ = await asyncio.to_thread(
                validate_odrl_against_shacl, odrl_content, shacl_path
            )
            score = (total_constraints - num_violations) / total_constraints
            return max(0, score)
        except Exception as e:
            print(f"è¯­æ³•éªŒè¯å¤±è´¥ï¼Œå°†è¿”å› 0.0 åˆ†ã€‚é”™è¯¯: {e}")
            return 0.0

async def run_semantic_identification_async(identifier_llm, policy_text: str) -> List[str]:
    """
    ä½¿ç”¨ "è£åˆ¤1 (è¯†åˆ«å™¨)" æå–è¯­ä¹‰ç‚¹åˆ—è¡¨ã€‚
    """
    async with io_semaphore:
        chain = IDENTIFICATION_PROMPT | identifier_llm
        try:
            result: SemanticPointIdentification = await chain.ainvoke({"policy_text": policy_text})
            return result.semantic_points
        except Exception as e:
            print(f"LLM è£åˆ¤1 (Identifier) æå–è¯­ä¹‰ç‚¹å¤±è´¥: {e}")
            return [] # è¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºå¤±è´¥

async def run_fine_grained_evaluation_async(evaluator_llm, policy_text: str, semantic_points: List[str], odrl_policy_str: str) -> float:
    """
    ä½¿ç”¨ "è£åˆ¤2 (è¯„ä¼°å™¨)" å¯¹ç»™å®šçš„è¯­ä¹‰ç‚¹åˆ—è¡¨è¿›è¡Œæ‰“åˆ†ã€‚
    """
    if not semantic_points: # å¦‚æœæ²¡æœ‰è¯†åˆ«å‡ºè¯­ä¹‰ç‚¹ï¼Œåˆ™æ— æ³•è¯„ä¼°
        return 0.0

    async with io_semaphore:
        chain = EVALUATION_PROMPT | evaluator_llm
        try:
            result: FineGrainedSemanticEvaluation = await chain.ainvoke({
                "policy_text": policy_text,
                "semantic_points_list": "\n".join(f"- {p}" for p in semantic_points),
                "odrl_policy_str": odrl_policy_str
            })
            
            score_map = {
                EvaluationCategory.PERFECTLY_MATCHED: 1.0,
                EvaluationCategory.PARTIALLY_MATCHED: 0.5,
                EvaluationCategory.MISMATCHED: 0.1,
                EvaluationCategory.MISSING: 0.0,
            }
            
            # --- MODIFICATION START ---
            # å³ä½¿LLMè¿”å›çš„è¯„ä¼°å•å…ƒæ•°ä¸åŒ¹é…ï¼Œæˆ‘ä»¬ä¾ç„¶ä»¥è¾“å…¥çš„è¯­ä¹‰ç‚¹æ€»æ•°ä¸ºå‡†æ¥è®¡ç®—æ€»åˆ†ï¼Œè¿™æ›´å…¬å¹³ã€‚
            achieved_score = sum(score_map[unit.evaluation] for unit in result.evaluated_units)
            total_possible_score = len(semantic_points) # <-- æ ¸å¿ƒä¿®æ­£ï¼šåˆ†æ¯æ°¸è¿œæ˜¯è£åˆ¤1ç»™å‡ºçš„æ•°é‡
            
            if len(result.evaluated_units) != len(semantic_points):
                print(f"è­¦å‘Š: è¯„ä¼°å™¨è¿”å›çš„å•å…ƒæ•°({len(result.evaluated_units)})ä¸è£åˆ¤1è¯†åˆ«çš„è¯­ä¹‰ç‚¹æ•°({len(semantic_points)})ä¸åŒ¹é…ã€‚å°†ä»¥è¯†åˆ«ç‚¹æ€»æ•°ä¸ºå‡†è®¡ç®—åˆ†æ•°ã€‚")
            # --- MODIFICATION END ---
            
            base_score = achieved_score / total_possible_score if total_possible_score > 0 else 0.0
            
            # åº”ç”¨å¹»è§‰æƒ©ç½š
            hallucination_penalty = len(result.hallucinated_elements) * 0.2
            final_score = base_score - hallucination_penalty
            
            return max(0.0, final_score)
        except Exception as e:
            print(f"LLM è£åˆ¤2 (Evaluator) è¯„ä¼°å¤±è´¥: {e}")
            return 0.0

async def get_semantic_score(policy_text: str, odrl_content: Dict, llm_clients: Dict[str, Any]) -> float:
    """
    ä¸€ä¸ªå®Œæ•´çš„è¯­ä¹‰è¯„ä¼°æµç¨‹ï¼šå…ˆè¯†åˆ«ï¼Œåè¯„ä¼°ã€‚
    """
    # æ­¥éª¤ 1: è£åˆ¤1è¿›è¡Œè¯­ä¹‰ç‚¹è¯†åˆ«
    semantic_points = await run_semantic_identification_async(llm_clients['identifier'], policy_text)
    
    # æ­¥éª¤ 2: è£åˆ¤2åŸºäºè¯†åˆ«ç»“æœè¿›è¡Œè¯„ä¼°
    odrl_str = json.dumps(odrl_content)
    score = await run_fine_grained_evaluation_async(llm_clients['evaluator'], policy_text, semantic_points, odrl_str)
    
    return score

# ... (ä¿ç•™ run_syntax_validation_async, run_semantic_identification_async, ç­‰è¾…åŠ©å‡½æ•°) ...

# --- NEW FUNCTION: Replaces evaluate_single_policy ---
async def evaluate_single_usecase(doc: Dict, llm_clients: Dict[str, Any]) -> Dict:
    """
    å¯¹å•ä¸ªUsecaseçš„æ‰€æœ‰ç­–ç•¥è¿›è¡Œè¯„ä¼°ã€‚
    - è¯­ä¹‰è¯„ä¼°ï¼šé‡‡ç”¨æ•´ä½“è¯„ä¼°æ³•ï¼Œå°†æ‰€æœ‰ODRLè§†ä¸ºä¸€ä¸ªæ•´ä½“ã€‚
    - è¯­æ³•è¯„ä¼°ï¼šå¯¹æ¯ä¸ªODRLå•ç‹¬è¯„åˆ†ï¼Œç„¶åå–å¹³å‡å€¼ã€‚
    """
    usecase_key = doc['usecase_key']
    # ä¼˜å…ˆä½¿ç”¨ "rewritten_usecase"ï¼Œå¦åˆ™å›é€€åˆ° "usecase_text"
    usecase_text = doc.get("rewritten_usecase") or doc.get("usecase_text")
    
    if not usecase_text:
        print(f"è­¦å‘Š: Usecase '{usecase_key}' ç¼ºå°‘ usecase_text å’Œ rewritten_usecaseï¼Œæ— æ³•è¿›è¡Œè¯­ä¹‰è¯„ä¼°ã€‚")
        # è¿”å›ä¸€ä¸ªåŒ…å«usecaseä¿¡æ¯çš„ç©ºåˆ†æ•°ç»“æ„
        return {
            "usecase_key": usecase_key,
            "category": "unknown",
            "reflection_attempts": 0,
            "scores": {"syntactic": {s: 0.0 for s in ODRL_STRATEGIES}, "semantic": {s: 0.0 for s in ODRL_STRATEGIES}}
        }

    policies = doc.get("policies", [])
    usecase_scores = {"syntactic": {}, "semantic": {}}
    
    # --- 1. æ•´ä½“è¯­ä¹‰è¯„ä¼° (Holistic Semantic Evaluation) ---
    # é¦–å…ˆï¼Œä¸€æ¬¡æ€§ä»Usecaseæ€»æ–‡æœ¬ä¸­æå–æ‰€æœ‰è¯­ä¹‰ç‚¹
    semantic_points = await run_semantic_identification_async(llm_clients['identifier'], usecase_text)
    
    semantic_tasks = {}
    for strategy_name, odrl_field in ODRL_STRATEGIES.items():
        # æ”¶é›†è¯¥ç­–ç•¥ä¸‹æ‰€æœ‰æœ‰æ•ˆçš„ ODRL policies
        odrl_collection = [
            p.get(odrl_field) for p in policies 
            if p.get(odrl_field) and not isinstance(p.get(odrl_field), dict) or "error" not in p.get(odrl_field)
        ]
        
        if not odrl_collection:
            # å¦‚æœè¯¥ç­–ç•¥æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆODRLï¼Œè¯­ä¹‰åˆ†ä¸º0
            semantic_tasks[strategy_name] = return_zero()
        else:
            # å°†æ‰€æœ‰ODRLåˆå¹¶æˆä¸€ä¸ªJSONå­—ç¬¦ä¸²ï¼ˆåˆ—è¡¨å½¢å¼ï¼‰
            odrl_str = json.dumps(odrl_collection)
            # åˆ›å»ºè¯„ä¼°ä»»åŠ¡
            semantic_tasks[strategy_name] = run_fine_grained_evaluation_async(
                llm_clients['evaluator'], usecase_text, semantic_points, odrl_str
            )
            
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è¯­ä¹‰è¯„ä¼°ä»»åŠ¡
    semantic_results = await asyncio.gather(*semantic_tasks.values())
    usecase_scores["semantic"] = dict(zip(semantic_tasks.keys(), semantic_results))

    # --- 2. å¹³å‡è¯­æ³•è¯„ä¼° (Averaged Syntactic Evaluation) ---
    # è¯­æ³•è¯„ä¼°ä»éœ€é€ä¸ªpolicyè¿›è¡Œï¼Œç„¶åå–å¹³å‡
    syn_scores_by_strategy = defaultdict(list)
    syntax_tasks = []
    task_info = [] # ç”¨äºæ˜ å°„ç»“æœ

    for policy in policies:
        odrl_type = policy.get("type")
        if odrl_type in TOTAL_CONSTRAINTS_BY_TYPE:
            total_constraints = TOTAL_CONSTRAINTS_BY_TYPE[odrl_type]
            shacl_path = SHACL_PATHS[odrl_type]
            for strategy_name, odrl_field in ODRL_STRATEGIES.items():
                odrl_content = policy.get(odrl_field)
                is_invalid = not odrl_content or (isinstance(odrl_content, dict) and "error" in odrl_content)
                
                task_info.append(strategy_name)
                if is_invalid:
                    syntax_tasks.append(return_zero())
                else:
                    syntax_tasks.append(run_syntax_validation_async(odrl_content, shacl_path, total_constraints))

    if syntax_tasks:
        syntax_results = await asyncio.gather(*syntax_tasks)
        for strategy, score in zip(task_info, syntax_results):
            syn_scores_by_strategy[strategy].append(score)

    for strategy_name in ODRL_STRATEGIES.keys():
        scores = syn_scores_by_strategy.get(strategy_name, [])
        usecase_scores["syntactic"][strategy_name] = sum(scores) / len(scores) if scores else 0.0

    # --- 3. ç»„è£…æœ€ç»ˆç»“æœ ---
    category = "unknown"
    if usecase_key.startswith("su_"): category = "simple"
    elif usecase_key.startswith("cu_j_"): category = "concurrent"
    elif usecase_key.startswith("cu_p_"): category = "progressive"
    
    # è®¡ç®—å¹³å‡åæ€æ¬¡æ•°
    reflection_attempts = [p.get("reflection_attempts_validation", 0) for p in policies]
    avg_reflection = sum(reflection_attempts) / len(reflection_attempts) if reflection_attempts else 0

    return {
        "usecase_key": usecase_key,
        "category": category,
        "reflection_attempts": avg_reflection,
        "scores": usecase_scores
    }

# --- MODIFIED FUNCTION: Replaces the old evaluate_policies ---
async def evaluate_policies(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹2: å¹¶è¡Œè¯„ä¼°æ‰€æœ‰ Usecases çš„è¯­æ³•å’Œè¯­ä¹‰å¾—åˆ†"""
    print(f"\n--- èŠ‚ç‚¹: è¯„ä¼° Usecases (å…± {len(state['documents'])} ä¸ª) ---")
    
    # æ–°é€»è¾‘: å¯¹æ¯ä¸ªæ–‡æ¡£ï¼ˆUsecaseï¼‰åˆ›å»ºä¸€ä¸ªè¯„ä¼°ä»»åŠ¡
    tasks = [evaluate_single_usecase(doc, state['llm_clients']) for doc in state['documents']]
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰Usecaseçš„è¯„ä¼°
    processed_results = await asyncio.gather(*tasks)

    state['processed_results'] = processed_results
    print(f"è¯„ä¼°å®Œæˆï¼Œå…±å¤„ç† {len(processed_results)} ä¸ª Usecasesã€‚")
    return state

# --- MODIFIED FUNCTION: Simplified aggregation logic ---
def aggregate_and_save_results(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹3: èšåˆæ‰€æœ‰å¾—åˆ†å¹¶ä¿å­˜åˆ°æ–‡ä»¶"""
    print("\n--- èŠ‚ç‚¹: èšåˆç»“æœ & ä¿å­˜æ–‡ä»¶ ---")
    
    # æ–°çš„æ•°æ®ç»“æ„å·²ç»æ˜¯Usecaseçº§åˆ«çš„äº†ï¼Œå¯ä»¥ç›´æ¥æŒ‰ç±»åˆ«èšåˆ
    category_level_data = defaultdict(lambda: {"reflection_attempts": [], "syntactic": defaultdict(list), "semantic": defaultdict(list)})
    
    # ç›´æ¥éå†å¤„ç†å¥½çš„Usecaseç»“æœ
    for usecase_result in state['processed_results']:
        # åŒæ—¶å¡«å……ç‰¹å®šåˆ†ç±»å’Œ'all'åˆ†ç±»
        for category in [usecase_result['category'], 'all']: 
            category_level_data[category]['reflection_attempts'].append(usecase_result['reflection_attempts'])
            for s_name, score in usecase_result['scores']['syntactic'].items():
                category_level_data[category]['syntactic'][s_name].append(score)
            for s_name, score in usecase_result['scores']['semantic'].items():
                category_level_data[category]['semantic'][s_name].append(score)

    final_results = {}
    for category, data in category_level_data.items():
        final_results[category] = {"average_reflection_attempts": sum(data['reflection_attempts']) / len(data['reflection_attempts']) if data['reflection_attempts'] else 0, "performance_by_strategy": {}}
        for s_name in ODRL_STRATEGIES.keys():
            syn_scores, sem_scores = data['syntactic'][s_name], data['semantic'][s_name]
            final_results[category]["performance_by_strategy"][s_name] = {
                "syntactic_score": f"{sum(syn_scores) / len(syn_scores):.2%}" if syn_scores else "N/A",
                "semantic_score": f"{sum(sem_scores) / len(sem_scores):.2%}" if sem_scores else "N/A",
            }

    output_data = {"metadata": {"source_database": state['db_name'], "source_collection": state['collection_name']}, "results": final_results}

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    OUTPUT_RESULTS_PATH.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_RESULTS_PATH, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=4, ensure_ascii=False)

    print(f"èšåˆå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {OUTPUT_RESULTS_PATH}")
    state['final_aggregated_results'] = output_data
    return state

# --- æ„å»º LangGraph å·¥ä½œæµ ---
workflow = StateGraph(EvaluationState)
workflow.add_node("initialize_and_fetch", initialize_and_fetch_data)
workflow.add_node("evaluate_policies", evaluate_policies)
workflow.add_node("aggregate_and_save", aggregate_and_save_results)
workflow.set_entry_point("initialize_and_fetch")
workflow.add_edge("initialize_and_fetch", "evaluate_policies")
workflow.add_edge("evaluate_policies", "aggregate_and_save")
workflow.add_edge("aggregate_and_save", END)
app = workflow.compile()

# --- ä¸»æ‰§è¡Œå‡½æ•° ---
async def main():
    initial_state = {"mongo_uri": MONGO_URI, "db_name": MONGO_DB_NAME, "collection_name": COLLECTION_NAME}
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ LangGraph å·¥ä½œæµ...")
    final_state = await app.ainvoke(initial_state)
    print("\nâœ… å·¥ä½œæµæ‰§è¡Œå®Œæ¯•ã€‚")
    print("\n--- æœ€ç»ˆè¯„ä¼°ç»“æœ ---")
    print(json.dumps(final_state.get('final_aggregated_results', {}), indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())