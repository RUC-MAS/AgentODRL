import asyncio
import json
import ast
from pathlib import Path
from typing import List, Dict, TypedDict, Any
from collections import defaultdict

# --- Langchain & LangGraph æ ¸å¿ƒç»„ä»¶ ---
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END

# --- å¯¼å…¥æ‚¨çš„çœŸå®æ¨¡å— ---
from mongodb import MongoDBManager
from ODRL_Check import validate_odrl_against_shacl

from langchain_core.output_parsers import StrOutputParser

# --- ç”¨æˆ·éœ€è¦é…ç½®çš„å¸¸é‡ ---

# MongoDB é…ç½®
MONGO_URI = "mongodb://localhost:27017/"
MONGO_DB_NAME = "odrl3_final"
COLLECTION_NAME = "e1_41" 

# OpenAI API Key (è¯·ç¡®ä¿ç¯å¢ƒå˜é‡ OPENAI_API_KEY å·²è®¾ç½®)
# æˆ–è€…å–æ¶ˆä¸‹ä¸€è¡Œæ³¨é‡Šå¹¶æä¾›æ–‡ä»¶è·¯å¾„
API_KEY_PATH = r"C:\Users\34085\Desktop\Agent\ALL_API_KEY.txt"

# SHACL æ–‡ä»¶è·¯å¾„ (çœŸå®è·¯å¾„)
SHACL_PATHS = {
    "set": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Rule_Shapes.ttl",
    "offer": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Offer_Shape.ttl",
    "agreement": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Agreement_Shape.ttl",
}

# ODRL ç±»å‹å¯¹åº”çš„æ€»çº¦æŸæ•°é‡
TOTAL_CONSTRAINTS_BY_TYPE = {
    "set": 29,
    "offer": 23,
    "agreement": 24,
}

# ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„
OUTPUT_RESULTS_PATH = Path(r"ODRL_V3\result\3e\e1_41_r2.json")

# å®šä¹‰éœ€è¦è¯„ä¼°çš„ ODRL ç­–ç•¥å­—æ®µå (ä¸Mongoæ–‡æ¡£å­—æ®µå®Œå…¨å¯¹åº”)
ODRL_STRATEGIES = {
    "ontology": 'initial_odrl',
    "vldb": 'final_odrl_branch_A_constraint',
    "vldb_semantic": 'enhanced_odrl_after_constraint',
    "semantic_syntactic": 'final_odrl_branch_B_validation'
}

# LLM è£åˆ¤å›¢é…ç½®
LLM_JUDGE_COUNT = 2

# æ–°å¢ï¼šå…¨å±€æœ€å¤§å¹¶å‘æ•°é‡æ§åˆ¶
# I/Oå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚APIè°ƒç”¨ï¼‰çš„å¹¶å‘é™åˆ¶
MAX_IO_CONCURRENCY = 50  
io_semaphore = asyncio.Semaphore(MAX_IO_CONCURRENCY)

# CPUå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚SHACLéªŒè¯ï¼‰çš„å¹¶å‘é™åˆ¶
# é€šå¸¸è®¾ç½®ä¸ºæœºå™¨çš„CPUæ ¸å¿ƒæ•°
MAX_CPU_CONCURRENCY = 8 
cpu_semaphore = asyncio.Semaphore(MAX_CPU_CONCURRENCY)

# --- Pydantic æ¨¡å‹å®šä¹‰ (å¤ç”¨è‡ªåŸä»£ç ) ---
class SemanticEvaluation(BaseModel):
    """ç”¨äºè§„èŒƒè¯­ä¹‰è¯„ä¼°ç»“æœçš„æ•°æ®ç»“æ„ï¼Œç¬¦åˆè¯­ä¹‰ä¸€è‡´æ€§å¾—åˆ†è®¡ç®—é€»è¾‘"""
    total_semantic_units: int = Field(
        ...,
        description="ä»åŸå§‹policyæ–‡æœ¬ä¸­åˆ†æå‡ºçš„æ‰€æœ‰ç‹¬ç«‹è¯­ä¹‰ç‚¹çš„æ€»æ•°é‡ã€‚æ¯ä¸ªè¯­ä¹‰ç‚¹ä»£è¡¨policyä¸­çš„ä¸€ä¸ªå…³é”®ä¿¡æ¯å…ƒç´ ï¼ˆå®ä½“ã€è§„åˆ™ã€æ¡ä»¶ã€å±æ€§ç­‰ï¼‰ï¼Œä¸”ä¸å¯å†åˆ†"
    )
    correctly_reflected_units: int = Field(
        ...,
        description="åœ¨ODRLç­–ç•¥ä¸­è¢«å‡†ç¡®ã€å®Œæ•´è¡¨è¾¾å‡ºæ¥çš„è¯­ä¹‰ç‚¹çš„æ•°é‡ã€‚å‡†ç¡®è¡¨è¾¾æŒ‡ODRLä¸­æœ‰å¯¹åº”å…ƒç´ ä¸”è¯­ä¹‰ä¸€è‡´"
    )
    missing_or_incorrect_units: List[str] = Field(
        ...,
        description="æœªè¢«æ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹æè¿°åˆ—è¡¨ï¼Œè¯´æ˜å“ªäº›è¯­ä¹‰ç‚¹åœ¨ODRLä¸­ç¼ºå¤±æˆ–è¡¨è¾¾é”™è¯¯"
    )

# --- Prompt å®šä¹‰ (ä¿®æ”¹) ---

# åŸæœ‰çš„ LORA_EXTRACTION_PROMPT å·²è¢«ç§»é™¤

# ä¿®æ”¹: ç”¨äºLLMè£åˆ¤è¯„ä¼°çš„Promptï¼Œç°åœ¨å®ƒæ¥æ”¶é¢„å…ˆæå–å¥½çš„è¯­ä¹‰ç‚¹åˆ—è¡¨
SEMANTIC_JUDGE_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
"""
æ‚¨æ˜¯ä¸€ä½ç²¾é€šODRLçš„ä¸“å®¶è£åˆ¤ã€‚æ‚¨çš„ä»»åŠ¡æ˜¯**ä¸¥æ ¼ä¾æ®**ç»™å®šçš„â€œæ ¸å¿ƒè¯­ä¹‰ç‚¹åˆ—è¡¨â€ï¼Œæ¥è¯„ä¼°â€œODRLç­–ç•¥â€æ˜¯å¦å‡†ç¡®åæ˜ äº†è¿™äº›è¯­ä¹‰ç‚¹ã€‚

**æ ¸å¿ƒä»»åŠ¡ä¸æ€è€ƒæ­¥éª¤ (è¯·åœ¨å†…å¿ƒä¸€æ­¥æ­¥æ‰§è¡Œ):**
1.  **å›ºå®šæ€»æ•°**: â€œæ ¸å¿ƒè¯­ä¹‰ç‚¹åˆ—è¡¨â€ä¸­çš„é¡¹ç›®æ€»æ•°æ˜¯ `{total_points}`ã€‚è¿™æ˜¯è¯„ä¼°çš„æ€»åˆ†æ¯ï¼Œæ— éœ€æ‚¨åˆ¤æ–­ã€‚
2.  **é€ä¸€æ ¸å¯¹**: éå†â€œæ ¸å¿ƒè¯­ä¹‰ç‚¹åˆ—è¡¨â€ä¸­çš„**æ¯ä¸€ä¸ªè¯­ä¹‰ç‚¹**ã€‚
3.  **æŸ¥æ‰¾æ˜ å°„**: å¯¹äºå½“å‰è¯­ä¹‰ç‚¹ï¼Œåœ¨â€œODRLç­–ç•¥â€çš„JSONå†…å®¹ä¸­æŸ¥æ‰¾æ˜¯å¦æœ‰ç›´æ¥æˆ–é—´æ¥çš„ã€è¯­ä¹‰å®Œå…¨ä¸€è‡´çš„è¡¨è¾¾ã€‚
4.  **åˆ¤å®šå¯¹é”™**:
    -   å¦‚æœæ‰¾åˆ°äº†å®Œå…¨å¯¹åº”çš„è¡¨è¾¾ï¼Œåˆ™è®°ä¸ºâ€œæ­£ç¡®åæ˜ â€ã€‚
    -   å¦‚æœåœ¨ODRLç­–ç•¥ä¸­ç¼ºå¤±è¯¥è¯­ä¹‰ç‚¹ï¼Œæˆ–è¡¨è¾¾ä¸å®Œæ•´ã€ä¸å‡†ç¡®ã€æœ‰æ­§ä¹‰ï¼Œåˆ™è®°ä¸ºâ€œç¼ºå¤±æˆ–é”™è¯¯â€ã€‚
5.  **ç»Ÿè®¡ä¸è¾“å‡º**:
    -   `total_semantic_units`: **å¿…é¡»**å¡«å†™æ‚¨æ”¶åˆ°çš„æ€»æ•° `{total_points}`ã€‚
    -   `correctly_reflected_units`: å¡«å†™æ‚¨åœ¨ç¬¬4æ­¥ä¸­ç»Ÿè®¡å‡ºçš„â€œæ­£ç¡®åæ˜ â€çš„è¯­ä¹‰ç‚¹æ€»æ•°ã€‚
    -   `missing_or_incorrect_units`: åˆ—å‡ºæ‰€æœ‰è¢«åˆ¤å®šä¸ºâ€œç¼ºå¤±æˆ–é”™è¯¯â€çš„è¯­ä¹‰ç‚¹çš„**åŸå§‹æ–‡æœ¬**ã€‚

**è¾“å‡ºè¦æ±‚ï¼š**
è¯·ä¸¥æ ¼æŒ‰ç…§ `SemanticEvaluation` æ ¼å¼è¿”å›JSONç»“æœã€‚
"""),
    ("human",
     """
è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯è¿›è¡Œè¯­ä¹‰è¯„ä¼°ï¼š

ODRL ç­–ç•¥ (JSON-LD æ ¼å¼):
```{odrl_policy_str}```

æ ¸å¿ƒè¯­ä¹‰ç‚¹åˆ—è¡¨ (å…± {total_points} ç‚¹):
{semantic_points_list_str}
""")
])



# --- LangGraph å·¥ä½œæµçŠ¶æ€å®šä¹‰ ---
class EvaluationState(TypedDict):
    """å®šä¹‰å·¥ä½œæµä¸­ä¼ é€’çš„çŠ¶æ€"""
    mongo_uri: str
    db_name: str
    collection_name: str
    documents: List[Dict]
    structured_llm: Any
    processed_results: List[Dict]
    final_aggregated_results: Dict


# --- LangGraph èŠ‚ç‚¹å‡½æ•° ---

def initialize_llm_client():
    """åˆå§‹åŒ–LLMå’Œç»“æ„åŒ–è¾“å‡ºé“¾"""
    try:
        with open(API_KEY_PATH, "r", encoding='utf-8') as f:
            api_key = f.read().strip()
    except FileNotFoundError:
        raise ValueError(f"é”™è¯¯ï¼šç¯å¢ƒå˜é‡ 'OPENAI_API_KEY' æœªè®¾ç½®ï¼Œä¹Ÿæœªåœ¨ {API_KEY_PATH} æ‰¾åˆ°æ–‡ä»¶ã€‚")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­æä¾› API_KEY_PATH")

    llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.1, api_key=api_key, base_url="https://zzzzapi.com/v1") 
    return llm.with_structured_output(SemanticEvaluation)

async def initialize_and_fetch_data(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹1: åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼Œå¹¶ä»æ•°æ®åº“è·å–æ•°æ®"""
    print("--- èŠ‚ç‚¹: åˆå§‹åŒ– & è·å–æ•°æ® ---")
    state['structured_llm'] = initialize_llm_client()
    
    db_manager = MongoDBManager(mongo_uri=state['mongo_uri'], mongo_db_name=state['db_name'])
    
    # å®šä¹‰æŠ•å½±ä»¥ä»…è·å–æ‰€éœ€å­—æ®µï¼Œæé«˜æ•ˆç‡
    projection_fields = {
        "usecase_key": 1,
        "policies.type": 1,
        "policies.text": 1,
        "policies.reflection_attempts_validation": 1,
        "policies.semantic_points_from_lora": 1,  # <-- æ–°å¢ï¼šè·å–é¢„å­˜çš„è¯­ä¹‰ç‚¹
    }
    for odrl_field in ODRL_STRATEGIES.values():
        projection_fields[f"policies.{odrl_field}"] = 1
        
    state['documents'] = await db_manager.fetch_all_rules(
        collection_name=state['collection_name'], 
        projection=projection_fields
    )
    
    if not state['documents']:
        raise ValueError(f"ä»é›†åˆ '{state['collection_name']}' æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£ã€‚è¯·æ£€æŸ¥æ•°æ®åº“å’Œé›†åˆåç§°ã€‚")
        
    print(f"æˆåŠŸè·å– {len(state['documents'])} ä»½ usecase æ–‡æ¡£ã€‚")
    # å¯¹äºè„šæœ¬ç±»åº”ç”¨ï¼Œé€šå¸¸ä¸éœ€è¦æ˜¾å¼å…³é—­è¿æ¥
    # await db_manager.close_connection()
    return state

async def run_syntax_validation_async(odrl_content: Dict, shacl_path: str, total_constraints: int) -> float:
    """
    åœ¨ç‹¬ç«‹çš„çº¿ç¨‹ä¸­å¼‚æ­¥æ‰§è¡ŒCPUå¯†é›†çš„SHACLéªŒè¯ï¼Œå¹¶åº”ç”¨å¹¶å‘æ§åˆ¶ã€‚
    """
    async with cpu_semaphore:
        try:
            # asyncio.to_thread å°†åŒæ­¥å‡½æ•°æ”¾åˆ°ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œï¼Œé˜²æ­¢é˜»å¡
            # validate_odrl_against_shacl æ˜¯ä¸€ä¸ªåŒæ­¥å‡½æ•°
            _, _, num_violations, _ = await asyncio.to_thread(
                validate_odrl_against_shacl, odrl_content, shacl_path
            )
            score = (total_constraints - num_violations) / total_constraints
            return max(0, score)
        except Exception as e:
            print(f"è¯­æ³•éªŒè¯å¤±è´¥ï¼Œå°†è¿”å› 0.0 åˆ†ã€‚é”™è¯¯: {e}")
            return 0.0

async def run_semantic_evaluation_async(structured_llm, odrl_policy_str: str, semantic_points_from_lora: str, usecase_key: str, strategy_name: str) -> float:
    """
    ä½¿ç”¨LLMï¼Œæ ¹æ®ä»æ•°æ®åº“ä¸­è·å–çš„é¢„å®šä¹‰è¯­ä¹‰ç‚¹åˆ—è¡¨ï¼Œè®¡ç®—å•æ¬¡è¯­ä¹‰å¾—åˆ†ã€‚
    """
    # å®‰å…¨åœ°å°†å­—ç¬¦ä¸²å½¢å¼çš„åˆ—è¡¨è½¬æ¢ä¸ºPythonåˆ—è¡¨
    try:
        # ast.literal_evalæ¯”json.loadsæ›´å®‰å…¨ï¼Œå¯ä»¥å¤„ç†å•å¼•å·ç­‰Pythonç‰¹æœ‰æ ¼å¼
        semantic_points_list = ast.literal_eval(semantic_points_from_lora)
        if not isinstance(semantic_points_list, list):
             raise ValueError("Parsed data is not a list.")
    except (ValueError, SyntaxError, TypeError):
        print(f"é”™è¯¯: æ— æ³•è§£æsemantic_points_from_loraå­—æ®µï¼Œå®ƒä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„åˆ—è¡¨å­—ç¬¦ä¸²ã€‚å†…å®¹: '{semantic_points_from_lora}'ã€‚å°†è¿”å› 0.0 åˆ†ã€‚")
        return 0.0

    if not semantic_points_list:
        print("è­¦å‘Šï¼šè¯­ä¹‰ç‚¹åˆ—è¡¨ä¸ºç©ºã€‚å°†è¿”å› 0.0 åˆ†ã€‚")
        return 0.0
    
    total_units = len(semantic_points_list)

    # --- æ–°å¢æ‰“å°è¯­å¥ ---
    print(f"  - [è¯­ä¹‰è¯„ä¼°] Usecase: {usecase_key}, ç­–ç•¥: {strategy_name}, è¯­ä¹‰ç‚¹æ•°: {total_units}")
    # ------------------

    # å°†åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå¸¦ç¼–å·çš„å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿LLMé˜…è¯»
    semantic_points_display_str = "\n".join(f"{i+1}. {point}" for i, point in enumerate(semantic_points_list))

    async with io_semaphore:
        try:
            # å‡†å¤‡å¹¶è°ƒç”¨è£åˆ¤é“¾
            judge_chain = SEMANTIC_JUDGE_PROMPT | structured_llm
            result: SemanticEvaluation = await judge_chain.ainvoke({
                "odrl_policy_str": odrl_policy_str,
                "total_points": total_units,
                "semantic_points_list_str": semantic_points_display_str
            })

            # ç›´æ¥ä½¿ç”¨æˆ‘ä»¬é¢„å…ˆè®¡ç®—çš„æ€»æ•°ä½œä¸ºåˆ†æ¯ï¼Œç¡®ä¿ç»“æœå¯é 
            correct_units = min(result.correctly_reflected_units, total_units)
            return correct_units / total_units if total_units > 0 else 0.0

        except Exception as e:
            print(f"LLM è¯­ä¹‰è¯„ä¼°æµç¨‹å¤±è´¥ï¼Œå°†è¿”å› 0.0 åˆ†ã€‚é”™è¯¯: {e}")
            return 0.0

async def evaluate_single_policy(policy: Dict, structured_llm: Any, usecase_key: str) -> Dict:
    """
    å¯¹å•ä¸ªpolicyçš„æ‰€æœ‰ç­–ç•¥è¿›è¡Œå¹¶è¡Œçš„è¯­æ³•å’Œè¯­ä¹‰è¯„ä¼°ã€‚
    """
    policy_scores = {"syntactic": {}, "semantic": {}}
    syntax_tasks = {}
    semantic_tasks = {}

    # 1. ä¸ºæ‰€æœ‰éœ€è¦è®¡ç®—çš„ä»»åŠ¡åˆ›å»ºåç¨‹
    odrl_type = policy.get("type")
    if odrl_type in TOTAL_CONSTRAINTS_BY_TYPE:
        total_constraints = TOTAL_CONSTRAINTS_BY_TYPE[odrl_type]
        shacl_path = SHACL_PATHS[odrl_type]

        for strategy_name, odrl_field in ODRL_STRATEGIES.items():
            if odrl_content := policy.get(odrl_field):
                # åˆ›å»ºè¯­æ³•ä»»åŠ¡
                syntax_tasks[strategy_name] = run_syntax_validation_async(
                    odrl_content, shacl_path, total_constraints
                )
                
                # åˆ›å»ºè¯­ä¹‰ä»»åŠ¡ï¼ˆæ¯ä¸ªè£åˆ¤ä¸€ä¸ªï¼‰ï¼Œå‰ææ˜¯å­˜åœ¨è¯­ä¹‰ç‚¹å­—æ®µ
                odrl_str = json.dumps(odrl_content)
                if semantic_points_str := policy.get("semantic_points_from_lora"):
                    semantic_tasks[strategy_name] = [
                        run_semantic_evaluation_async(
                            structured_llm,
                            odrl_str,
                            semantic_points_str,  # <-- ä¼ é€’ä»æ•°æ®åº“è·å–çš„è¯­ä¹‰ç‚¹å­—ç¬¦ä¸²
                            usecase_key,       # <-- ä¿®æ”¹ï¼šä¼ é€’ usecase_key
                            strategy_name      # <-- ä¿®æ”¹ï¼šä¼ é€’ strategy_name
                        )
                        for _ in range(LLM_JUDGE_COUNT)
                    ]
                else:
                    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰è¯¥å­—æ®µï¼Œåˆ™ä¸è¿›è¡Œè¯­ä¹‰è¯„ä¼°
                    print(f"è­¦å‘Š: Usecase '{usecase_key}' çš„ç­–ç•¥ '{strategy_name}' ç¼ºå°‘ 'semantic_points_from_lora' å­—æ®µã€‚è·³è¿‡è¯­ä¹‰è¯„ä¼°ã€‚")
                    semantic_tasks[strategy_name] = [] # ç¡®ä¿é”®å­˜åœ¨ä½†ä»»åŠ¡åˆ—è¡¨ä¸ºç©º

    # 2. å¹¶å‘æ‰§è¡Œæ‰€æœ‰å·²åˆ›å»ºçš„ä»»åŠ¡
    # å°†æ‰€æœ‰ä»»åŠ¡åç¨‹æ”¶é›†åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œä»¥ä¾¿gatherè°ƒç”¨
    all_tasks_to_run = list(syntax_tasks.values())
    for judge_tasks in semantic_tasks.values():
        all_tasks_to_run.extend(judge_tasks)

    # å¦‚æœæ²¡æœ‰ä»»ä½•ä»»åŠ¡ï¼Œç›´æ¥è¿”å›
    if not all_tasks_to_run:
        return policy_scores

    # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    all_results = await asyncio.gather(*all_tasks_to_run)
    
    # 3. è§£æç»“æœ
    result_index = 0
    # è§£æè¯­æ³•å¾—åˆ†
    for strategy_name in syntax_tasks.keys():
        policy_scores["syntactic"][strategy_name] = all_results[result_index]
        result_index += 1
    
    # è§£æè¯­ä¹‰å¾—åˆ†
    for strategy_name, judge_tasks in semantic_tasks.items():
        if not judge_tasks:
            continue
        
        # æå–å±äºå½“å‰ç­–ç•¥çš„è¯­ä¹‰å¾—åˆ†ç»“æœ
        judge_scores = all_results[result_index : result_index + len(judge_tasks)]
        result_index += len(judge_tasks)
        
        # è®¡ç®—å¹³å‡åˆ†
        if judge_scores:
            policy_scores["semantic"][strategy_name] = sum(judge_scores) / len(judge_scores)

    return policy_scores

async def evaluate_policies(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹2: å¹¶è¡Œè¯„ä¼°æ‰€æœ‰ policies çš„è¯­æ³•å’Œè¯­ä¹‰å¾—åˆ†"""
    print(f"\n--- èŠ‚ç‚¹: è¯„ä¼° Policies (å…± {len(state['documents'])} ä¸ª Usecases) ---")
    # ä¿®æ”¹ï¼šå°† usecase_key ä¼ é€’ç»™ evaluate_single_policy
    tasks = [
        evaluate_single_policy(policy, state['structured_llm'], doc['usecase_key'])
        for doc in state['documents'] 
        for policy in doc.get("policies", [])
    ]
    all_policy_scores = await asyncio.gather(*tasks)
    
    processed_results = []
    policy_counter = 0
    for doc in state['documents']:
        usecase_key = doc['usecase_key']
        category = "unknown"
        if usecase_key.startswith("su_"): category = "simple"
        elif usecase_key.startswith("cu_j_"): category = "concurrent"
        elif usecase_key.startswith("cu_p_"): category = "progressive"
        
        for policy in doc.get("policies", []):
            processed_results.append({
                "usecase_key": usecase_key, "category": category,
                "reflection_attempts": policy.get("reflection_attempts_validation", 0),
                "scores": all_policy_scores[policy_counter]
            })
            policy_counter += 1
            
    state['processed_results'] = processed_results
    print(f"è¯„ä¼°å®Œæˆï¼Œå…±å¤„ç† {len(processed_results)} ä¸ª policiesã€‚")
    return state

def aggregate_and_save_results(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹3: èšåˆæ‰€æœ‰å¾—åˆ†å¹¶ä¿å­˜åˆ°æ–‡ä»¶"""
    print("\n--- èŠ‚ç‚¹: èšåˆç»“æœ & ä¿å­˜æ–‡ä»¶ ---")
    # æŒ‰ usecase_key -> category èšåˆ
    usecase_level_data = defaultdict(lambda: {"category": "", "reflection_attempts": [], "syntactic": defaultdict(list), "semantic": defaultdict(list)})
    for res in state['processed_results']:
        key = res['usecase_key']
        usecase_level_data[key]['category'] = res['category']
        usecase_level_data[key]['reflection_attempts'].append(res['reflection_attempts'])
        for s_name, score in res['scores']['syntactic'].items(): usecase_level_data[key]['syntactic'][s_name].append(score)
        for s_name, score in res['scores']['semantic'].items(): usecase_level_data[key]['semantic'][s_name].append(score)

    usecase_averages = {key: {"category": data['category'],
        "avg_reflection": sum(data['reflection_attempts']) / len(data['reflection_attempts']) if data['reflection_attempts'] else 0,
        "avg_syntactic": {s_name: sum(scores) / len(scores) for s_name, scores in data['syntactic'].items() if scores},
        "avg_semantic": {s_name: sum(scores) / len(scores) for s_name, scores in data['semantic'].items() if scores},
    } for key, data in usecase_level_data.items()}

    category_level_data = defaultdict(lambda: {"reflection_attempts": [], "syntactic": defaultdict(list), "semantic": defaultdict(list)})
    for key, avg_data in usecase_averages.items():
        for category in [avg_data['category'], 'all']: # åŒæ—¶å¡«å……ç‰¹å®šåˆ†ç±»å’Œ'all'åˆ†ç±»
            category_level_data[category]['reflection_attempts'].append(avg_data['avg_reflection'])
            for s_name, score in avg_data['avg_syntactic'].items(): category_level_data[category]['syntactic'][s_name].append(score)
            for s_name, score in avg_data['avg_semantic'].items(): category_level_data[category]['semantic'][s_name].append(score)

    final_results = {}
    for category, data in category_level_data.items():
        final_results[category] = {"average_reflection_attempts": sum(data['reflection_attempts']) / len(data['reflection_attempts']) if data['reflection_attempts'] else 0, "performance_by_strategy": {}}
        for s_name in ODRL_STRATEGIES.keys():
            syn_scores, sem_scores = data['syntactic'][s_name], data['semantic'][s_name]
            final_results[category]["performance_by_strategy"][s_name] = {
                "syntactic_score": f"{sum(syn_scores) / len(syn_scores):.2%}" if syn_scores else "N/A",
                "semantic_score": f"{sum(sem_scores) / len(sem_scores):.2%}" if sem_scores else "N/A",
            }
    
    output_data = {"metadata": {"source_database": state['db_name'], "source_collection": state['collection_name']}, "results": final_results}
    
    with open(OUTPUT_RESULTS_PATH, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=4, ensure_ascii=False)
        
    print(f"èšåˆå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {OUTPUT_RESULTS_PATH}")
    state['final_aggregated_results'] = output_data
    return state

# --- æ„å»º LangGraph å·¥ä½œæµ ---
workflow = StateGraph(EvaluationState)
workflow.add_node("initialize_and_fetch", initialize_and_fetch_data)
workflow.add_node("evaluate_policies", evaluate_policies)
workflow.add_node("aggregate_and_save", aggregate_and_save_results)
workflow.set_entry_point("initialize_and_fetch")
workflow.add_edge("initialize_and_fetch", "evaluate_policies")
workflow.add_edge("evaluate_policies", "aggregate_and_save")
workflow.add_edge("aggregate_and_save", END)
app = workflow.compile()

# --- ä¸»æ‰§è¡Œå‡½æ•° ---
async def main():
    initial_state = {"mongo_uri": MONGO_URI, "db_name": MONGO_DB_NAME, "collection_name": COLLECTION_NAME}
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ LangGraph å·¥ä½œæµ...")
    final_state = await app.ainvoke(initial_state)
    print("\nâœ… å·¥ä½œæµæ‰§è¡Œå®Œæ¯•ã€‚")
    print("\n--- æœ€ç»ˆè¯„ä¼°ç»“æœ ---")
    print(json.dumps(final_state.get('final_aggregated_results', {}), indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())