import asyncio
import json
import os
from pathlib import Path
from typing import List, Dict, TypedDict, Any
from collections import defaultdict

# --- Langchain & LangGraph æ ¸å¿ƒç»„ä»¶ ---
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END

# --- å¯¼å…¥æ‚¨çš„çœŸå®æ¨¡å— ---
from mongodb import MongoDBManager
from ODRL_Check import validate_odrl_against_shacl

# --- ç”¨æˆ·éœ€è¦é…ç½®çš„å¸¸é‡ ---

# MongoDB é…ç½®
MONGO_URI = "mongodb://localhost:27017/"
MONGO_DB_NAME = "odrl3_final"
COLLECTION_NAME = "e2_41nano_split_r"

# OpenAI API Key (è¯·ç¡®ä¿ç¯å¢ƒå˜é‡ OPENAI_API_KEY å·²è®¾ç½®)
# æˆ–è€…å–æ¶ˆä¸‹ä¸€è¡Œæ³¨é‡Šå¹¶æä¾›æ–‡ä»¶è·¯å¾„
API_KEY_PATH = r"C:\Users\34085\Desktop\Agent\ALL_API_KEY.txt"

# SHACL æ–‡ä»¶è·¯å¾„ (çœŸå®è·¯å¾„)
SHACL_PATHS = {
    "set": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Rule_Shapes.ttl",
    "offer": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Offer_Shape.ttl",
    "agreement": r"ODRL_V3\data_preparation\shacl_for_validation\ODRL_Agreement_Shape.ttl",
}

# ODRL ç±»å‹å¯¹åº”çš„æ€»çº¦æŸæ•°é‡
TOTAL_CONSTRAINTS_BY_TYPE = {
    "set": 29,
    "offer": 23,
    "agreement": 24,
}

# ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„
OUTPUT_RESULTS_PATH = Path(r"ODRL_V3\result\3e\e2\e2_41nano_split_V1.json")

# å®šä¹‰éœ€è¦è¯„ä¼°çš„ ODRL ç­–ç•¥å­—æ®µå (ä¸Mongoæ–‡æ¡£å­—æ®µå®Œå…¨å¯¹åº”)
ODRL_STRATEGIES = {
    "semantic_syntactic": 'final_odrl_branch_B_validation'
}

# æ–°å¢ï¼šå…¨å±€æœ€å¤§å¹¶å‘æ•°é‡æ§åˆ¶
# I/Oå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚APIè°ƒç”¨ï¼‰çš„å¹¶å‘é™åˆ¶
MAX_IO_CONCURRENCY = 50
io_semaphore = asyncio.Semaphore(MAX_IO_CONCURRENCY)

# CPUå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚SHACLéªŒè¯ï¼‰çš„å¹¶å‘é™åˆ¶
# é€šå¸¸è®¾ç½®ä¸ºæœºå™¨çš„CPUæ ¸å¿ƒæ•°
MAX_CPU_CONCURRENCY = 8
cpu_semaphore = asyncio.Semaphore(MAX_CPU_CONCURRENCY)

async def return_zero() -> float:
    """ä¸€ä¸ªç®€å•çš„å¼‚æ­¥å‡½æ•°ï¼Œç”¨äºåœ¨æ£€æµ‹åˆ°æ— æ•ˆODRLæ—¶è¿”å›0.0åˆ†ã€‚"""
    return 0.0

# --- Pydantic æ¨¡å‹å®šä¹‰ (å¤ç”¨è‡ªåŸä»£ç ) ---
class SemanticEvaluation(BaseModel):
    """ç”¨äºè§„èŒƒè¯­ä¹‰è¯„ä¼°ç»“æœçš„æ•°æ®ç»“æ„ï¼Œç¬¦åˆè¯­ä¹‰ä¸€è‡´æ€§å¾—åˆ†è®¡ç®—é€»è¾‘"""
    total_semantic_units: int = Field(
        ...,
        description="ä»åŸå§‹policyæ–‡æœ¬ä¸­åˆ†æå‡ºçš„æ‰€æœ‰ç‹¬ç«‹è¯­ä¹‰ç‚¹çš„æ€»æ•°é‡ã€‚æ¯ä¸ªè¯­ä¹‰ç‚¹ä»£è¡¨policyä¸­çš„ä¸€ä¸ªå…³é”®ä¿¡æ¯å…ƒç´ ï¼ˆå®ä½“ã€è§„åˆ™ã€æ¡ä»¶ã€å±æ€§ç­‰ï¼‰ï¼Œä¸”ä¸å¯å†åˆ†"
    )
    correctly_reflected_units: int = Field(
        ...,
        description="åœ¨ODRLç­–ç•¥ä¸­è¢«å‡†ç¡®ã€å®Œæ•´è¡¨è¾¾å‡ºæ¥çš„è¯­ä¹‰ç‚¹çš„æ•°é‡ã€‚å‡†ç¡®è¡¨è¾¾æŒ‡ODRLä¸­æœ‰å¯¹åº”å…ƒç´ ä¸”è¯­ä¹‰ä¸€è‡´"
    )
    missing_or_incorrect_units: List[str] = Field(
        ...,
        description="æœªè¢«æ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹æè¿°åˆ—è¡¨ï¼Œè¯´æ˜å“ªäº›è¯­ä¹‰ç‚¹åœ¨ODRLä¸­ç¼ºå¤±æˆ–è¡¨è¾¾é”™è¯¯"
    )

# --- æ–°å¢: "è£åˆ¤2" çš„ç²¾ç»†åŒ–è¯„ä¼°æ¨¡å‹ ---
from enum import Enum  # <-- æ–°å¢æ­¤è¡Œ

# ... å…¶ä»–ä»£ç ä¿æŒä¸å˜ ...

# --- æ–°å¢: "è£åˆ¤2" çš„ç²¾ç»†åŒ–è¯„ä¼°æ¨¡å‹ ---
class EvaluationCategory(str, Enum):
    """å®šä¹‰è¯­ä¹‰è¯„ä¼°çš„å››ä¸ªç­‰çº§"""
    PERFECTLY_MATCHED = "PERFECTLY_MATCHED"
    PARTIALLY_MATCHED = "PARTIALLY_MATCHED"
    MISMATCHED = "MISMATCHED"
    MISSING = "MISSING"

class DetailedSemanticUnit(BaseModel):
    """å¯¹å•ä¸ªè¯­ä¹‰ç‚¹çš„è¯¦ç»†è¯„ä¼°"""
    semantic_point_text: str = Field(..., description="ä»Policyæ–‡æœ¬ä¸­æå–çš„åŸå§‹è¯­ä¹‰ç‚¹ã€‚")
    evaluation: EvaluationCategory = Field(..., description="è¯¥è¯­ä¹‰ç‚¹åœ¨ODRLä¸­çš„åŒ¹é…ç¨‹åº¦è¯„ä¼°ã€‚")
    justification: str = Field(..., description="å¯¹å½“å‰è¯„ä¼°ç­‰çº§çš„ç®€è¦è§£é‡Šã€‚")

class FineGrainedSemanticEvaluation(BaseModel):
    """ç”¨äºè§„èŒƒ"è£åˆ¤2"è¾“å‡ºçš„ç²¾ç»†åŒ–è¯­ä¹‰è¯„ä¼°ç»“æœçš„æ•°æ®ç»“æ„"""
    identified_units: List[DetailedSemanticUnit] = Field(
        ...,
        description="å¯¹ä»Policyæ–‡æœ¬ä¸­è¯†åˆ«å‡ºçš„æ¯ä¸€ä¸ªè¯­ä¹‰ç‚¹è¿›è¡Œçš„è¯¦ç»†è¯„ä¼°åˆ—è¡¨ã€‚"
    )
    hallucinated_elements: List[str] = Field(
        default=[],
        description="åœ¨ODRLä¸­å­˜åœ¨ï¼Œä½†æ— æ³•åœ¨åŸå§‹Policyæ–‡æœ¬ä¸­æ‰¾åˆ°å¯¹åº”ä¾æ®çš„å…ƒç´ æè¿°åˆ—è¡¨ï¼ˆå¹»è§‰å†…å®¹ï¼‰ã€‚"
    )

# --- Prompt å®šä¹‰ (å¤ç”¨è‡ªåŸä»£ç ) ---
SEMANTIC_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
"""
æ‚¨æ˜¯ä¸€ä½ç²¾é€šODRLå’Œè‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸“å®¶ã€‚æ‚¨çš„ä»»åŠ¡æ˜¯ç²¾ç¡®è¯„ä¼°ç»™å®šçš„ODRLç­–ç•¥æ˜¯å¦å‡†ç¡®åæ˜ äº†åŸå§‹Policyæ–‡æœ¬ä¸­çš„æ‰€æœ‰è¯­ä¹‰ç‚¹ã€‚

**æ ¸å¿ƒä»»åŠ¡ï¼š**
1.  **è¯†åˆ«è¯­ä¹‰ç‚¹**: ä¸¥æ ¼éµå¾ªä¸‹è¿°çš„ **â€œè¯­ä¹‰ç‚¹æå–åè®®â€**ï¼Œåœ¨è„‘ä¸­è¯†åˆ«å‡º`Policy æ–‡æœ¬`ä¸­çš„æ‰€æœ‰åŸå­è¯­ä¹‰å•å…ƒã€‚
2.  **éªŒè¯æ˜ å°„**: å°†è¯†åˆ«å‡ºçš„æ¯ä¸ªè¯­ä¹‰ç‚¹ï¼Œé€ä¸€æ£€æŸ¥åœ¨`ODRLç­–ç•¥`ä¸­æ˜¯å¦æœ‰å¯¹åº”ä¸”è¯­ä¹‰ä¸€è‡´çš„è¡¨è¾¾ã€‚
3.  **é‡åŒ–ç»“æœ**: ç»Ÿè®¡æ€»è¯­ä¹‰ç‚¹æ•°é‡å’Œåœ¨ODRLä¸­è¢«æ­£ç¡®åæ˜ çš„æ•°é‡ï¼Œå¹¶åˆ—å‡ºæœªæ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹ã€‚

---
**è¯­ä¹‰ç‚¹æå–åè®® (Semantic Unit Extraction Protocol)**

**1. æ‰«æé”šç‚¹ (Scan Anchors):**
* **æˆæƒ/æ¥æ”¶å®ä½“**: å¿…é¡»ä¿ç•™å®Œæ•´çš„å®ä½“åç§° (ä¾‹å¦‚, "the Urban Planning Dept")ã€‚
* **åŠ¨ä½œåŠ¨è¯**: å¿…é¡»åŒ…å«æ‰€æœ‰ä¿®é¥°è¯å’Œå¦å®šè¯ (ä¾‹å¦‚, "securely process", "must not share")ã€‚
* **æ•°æ®èµ„äº§å¼•ç”¨**: å¿…é¡»åŒ…å«ç›¸å…³çš„æè¿°è¯ (ä¾‹å¦‚, "Traffic Data")ã€‚
* **æƒé™/ç¦æ­¢æ ‡è®°**: ä¾‹å¦‚, "grants", "prohibits"ã€‚
* **çº¦æŸé›†ç¾¤**: å¿…é¡»å°†æ—¶é—´ã€ç›®çš„ã€åœ°ç‚¹ã€æ•°é‡ç­‰çº¦æŸè§†ä¸ºä¸€ä¸ªä¸å¯åˆ†å‰²çš„æ•´ä½“ (ä¾‹å¦‚, "until 2025-12-31", "except PII data")ã€‚
* **ä¹‰åŠ¡çŸ­è¯­**: ä¾‹å¦‚, "must report", "is required to"ã€‚

**2. æå–è§„åˆ™ (Extraction Rules):**
* **âœ“ å¿ å®æ€§ (Fidelity)**: æå–æ—¶å¿…é¡»ä¿æŒåŸå§‹æ–‡æœ¬çš„ç¡®åˆ‡æªè¾ã€é¡ºåºå’Œå¤§å°å†™ã€‚
* **âœ“ å®Œæ•´æ€§ (Completeness)**: å¿…é¡»æ•è·å®Œæ•´çš„çŸ­è¯­ (ä¾‹å¦‚, å®Œæ•´çš„æ—¥æœŸ "2025-12-31")ã€‚
* **âœ“ å¤åˆå•å…ƒ (Compound Units)**: å¿…é¡»ä¿æŒé€»è¾‘å•å…ƒçš„å®Œæ•´æ€§ (ä¾‹å¦‚, "must not process externally" åº”è¢«è§†ä¸ºä¸€ä¸ªå•å…ƒ)ã€‚
* **âœ— æ’é™¤é¡¹ (Exclusion)**: å¿…é¡»å¿½ç•¥ç‹¬ç«‹çš„ã€æ— å®é™…è¯­ä¹‰çš„è¯­æ³•è¿æ¥è¯ (å¦‚ that, which, a, the ç­‰)ã€‚

**3. éªŒè¯ç¤ºä¾‹ (Validation Examples):**
* **âœ“ æœ‰æ•ˆè¯†åˆ«**
    * **æ–‡æœ¬**: "The Data Hub grants the Urban Planning Dept access to Traffic Data until 2025-12-31"
    * **åº”è¯†åˆ«çš„è¯­ä¹‰ç‚¹**: `["The Data Hub", "grants", "the Urban Planning Dept", "access", "Traffic Data", "until 2025-12-31"]`
* **âœ— æ— æ•ˆè¯†åˆ«**
    * **æ–‡æœ¬**: "Analytics teams may process sales records except PII data"
    * **é”™è¯¯è¯†åˆ«**: `["Analytics", "may process", "sales records", "except", "PII data"]`
    * **æ­£ç¡®è¯†åˆ«**: `["Analytics teams", "may process", "sales records", "except PII data"]` (åŸå› : "except PII data" æ˜¯ä¸€ä¸ªä¸å¯åˆ†å‰²çš„çº¦æŸå•å…ƒ)ã€‚
---

**è¯„ä¼°æ ‡å‡†ï¼š**
* **æ­£ç¡®åæ˜ **: ODRLä¸­æœ‰ç›´æ¥å¯¹åº”å…ƒç´ ä¸”è¯­ä¹‰å®Œå…¨åŒ¹é…ã€‚
* **æœªæ­£ç¡®åæ˜ **: ODRLä¸­ç¼ºå¤±å¯¹åº”å…ƒç´ ã€å…ƒç´ è¯­ä¹‰ä¸åŒ¹é…æˆ–ä¸å®Œæ•´ã€‚

**è¾“å‡ºè¦æ±‚ï¼š**
è¯·ä¸¥æ ¼æŒ‰ç…§`SemanticEvaluation`æ ¼å¼è¿”å›ç»“æœï¼ŒåŒ…å«ï¼š
1.  `total_semantic_units`: æ ¹æ®ä¸Šè¿°åè®®è¯†åˆ«å‡ºçš„è¯­ä¹‰ç‚¹æ€»æ•°ã€‚
2.  `correctly_reflected_units`: åœ¨ODRLä¸­è¢«æ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹æ•°é‡ã€‚
3.  `missing_or_incorrect_units`: æœªè¢«æ­£ç¡®åæ˜ çš„è¯­ä¹‰ç‚¹æè¿°åˆ—è¡¨ã€‚
**æ³¨æ„ï¼š`total_semantic_units` å¿…é¡»ç­‰äº `correctly_reflected_units` ä¸ `missing_or_incorrect_units` åˆ—è¡¨é•¿åº¦ä¹‹å’Œã€‚**
"""),
    ("human",
    """
è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯è¿›è¡Œè¯­ä¹‰è¯„ä¼°ï¼š

Policy æ–‡æœ¬:
```{policy_text}```

ODRL ç­–ç•¥ (JSON-LD æ ¼å¼):
```{odrl_policy_str}```
""")
])

FINE_GRAINED_SEMANTIC_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
"""
æ‚¨æ˜¯ä¸€ä½æå…¶ä¸¥è‹›å’Œç²¾å‡†çš„ODRLåˆ†æä¸“å®¶ï¼Œæ‹…ä»»â€œè£åˆ¤2â€çš„è§’è‰²ã€‚æ‚¨çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹æ–¹çš„â€œç²¾ç»†åŒ–è¯„åˆ†åè®®â€ï¼Œå¯¹ç»™å®šçš„ODRLç­–ç•¥è¿›è¡Œå¾®è§‚å±‚é¢çš„ã€å¸¦æœ‰æƒé‡çš„è¯„ä¼°ã€‚æ‚¨å¿…é¡»é€ä¸ªåˆ†æåœ¨`Policy æ–‡æœ¬`ä¸­è¯†åˆ«å‡ºçš„è¯­ä¹‰ç‚¹ï¼Œå¹¶è¯„ä¼°å…¶åœ¨ODRLä¸­çš„åæ˜ è´¨é‡ã€‚

---
**ç²¾ç»†åŒ–è¯„åˆ†åè®® (Fine-Grained Scoring Protocol)**

**1. è¯­ä¹‰ç‚¹è¯†åˆ«:**
é¦–å…ˆï¼Œå®Œå…¨å‚ç…§`Policy æ–‡æœ¬`ï¼Œè¯†åˆ«å‡ºæ‰€æœ‰ç‹¬ç«‹çš„ã€åŸå­çš„è¯­ä¹‰ç‚¹ã€‚

**2. é€ç‚¹è¯„ä¼°:**
å¯¹æ¯ä¸€ä¸ªè¯†åˆ«å‡ºçš„è¯­ä¹‰ç‚¹ï¼Œæ‚¨å¿…é¡»æ ¹æ®ä»¥ä¸‹å››ä¸ªç­‰çº§è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºç†ç”±ï¼š

* **PERFECTLY_MATCHED (å¾—åˆ†: 1.0):** ODRLä¸­çš„è¡¨è¿°å®Œå…¨ã€å‡†ç¡®ã€æ— æ­§ä¹‰åœ°åæ˜ äº†è¯¥è¯­ä¹‰ç‚¹çš„æ‰€æœ‰ä¿¡æ¯ã€‚
    * *ç¤ºä¾‹*: æ–‡æœ¬ "until 2025-12-31" å¯¹åº” ODRL `<odrl:constraint><odrl:rightOperand rdf:datatype="http://www.w3.org/2001/XMLSchema#date">2025-12-31</odrl:rightOperand>...</odrl:constraint>`ã€‚

* **PARTIALLY_MATCHED (å¾—åˆ†: 0.5):** ODRLä¸­åæ˜ äº†è¯­ä¹‰ç‚¹çš„æ ¸å¿ƒæ€æƒ³ï¼Œä½†å­˜åœ¨ä¿¡æ¯ç¼ºå¤±æˆ–è½»å¾®ä¸å‡†ç¡®ã€‚
    * *ç¤ºä¾‹*: æ–‡æœ¬ "the Urban Planning Dept" å¯¹åº” ODRL `assignee: "Urban Dept"` (åç§°ä¸å®Œæ•´)ã€‚æ–‡æœ¬ "securely process" å¯¹åº” ODRL `action: "process"` (ç¼ºå°‘äº†â€œsecurelyâ€è¿™ä¸€ä¿®é¥°)ã€‚

* **MISMATCHED (å¾—åˆ†: 0.1):** ODRLä¸­æœ‰çœ‹ä¼¼å¯¹åº”çš„å…ƒç´ ï¼Œä½†å…¶é€»è¾‘æˆ–å«ä¹‰ä¸åŸæ–‡å®Œå…¨é”™è¯¯ã€‚
    * *ç¤ºä¾‹*: æ–‡æœ¬è¦æ±‚â€œå…è®¸(grants)â€ï¼ŒODRLä¸­å´ä½¿ç”¨äº†â€œç¦æ­¢(prohibits)â€ã€‚æ–‡æœ¬è¦æ±‚â€œç›®çš„ä¸ºç§‘ç ”â€ï¼ŒODRLä¸­å´å†™æˆâ€œç›®çš„ä¸ºå•†ä¸šâ€ã€‚

* **MISSING (å¾—åˆ†: 0.0):** ODRLä¸­å®Œå…¨æ²¡æœ‰èƒ½å¯¹åº”ä¸Šè¯¥è¯­ä¹‰ç‚¹çš„ä»»ä½•ä¿¡æ¯ã€‚

**3. å¹»è§‰å†…å®¹æƒ©ç½š:**
æ£€æŸ¥ODRLä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•`Policy æ–‡æœ¬`ä¸­æœªæåŠçš„é™åˆ¶ã€æƒé™æˆ–å®ä½“ï¼ˆå³â€œå¹»è§‰â€å†…å®¹ï¼‰ã€‚æ¯å‘ç°ä¸€ä¸ªç‹¬ç«‹çš„å¹»è§‰å…ƒç´ ï¼Œå°±åœ¨æœ€ç»ˆæ€»åˆ†çš„åŸºç¡€ä¸Šè¿›è¡Œæ‰£åˆ†ã€‚

**4. è¾“å‡ºè¦æ±‚:**
æ‚¨å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ `FineGrainedSemanticEvaluation` JSONæ ¼å¼è¾“å‡ºç»“æœï¼Œå…¶ä¸­åŒ…å«ï¼š
1.  `identified_units`: ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å¯¹å•ä¸ªè¯­ä¹‰ç‚¹çš„`DetailedSemanticUnit`è¯„ä¼°ã€‚
2.  `hallucinated_elements`: ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œåˆ—å‡ºæ‰€æœ‰æ£€æµ‹åˆ°çš„å¹»è§‰å†…å®¹ã€‚
"""),
    ("human",
"""
è¯·æ ¹æ®â€œç²¾ç»†åŒ–è¯„åˆ†åè®®â€å¯¹ä»¥ä¸‹ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼š

Policy æ–‡æœ¬:
```{policy_text}```

ODRL ç­–ç•¥ (JSON-LD æ ¼å¼):
```{odrl_policy_str}```
""")
])


# --- LangGraph å·¥ä½œæµçŠ¶æ€å®šä¹‰ ---
class EvaluationState(TypedDict):
    """å®šä¹‰å·¥ä½œæµä¸­ä¼ é€’çš„çŠ¶æ€"""
    mongo_uri: str
    db_name: str
    collection_name: str
    documents: List[Dict]
    # ä¿®æ”¹: 'structured_llm' -> 'llm_clients'
    llm_clients: Dict[str, Any] # å°†æŒæœ‰ 'holistic' å’Œ 'fine_grained' ä¸¤ä¸ªå®¢æˆ·ç«¯
    processed_results: List[Dict]
    final_aggregated_results: Dict



# --- LangGraph èŠ‚ç‚¹å‡½æ•° ---

def initialize_llm_clients():
    """åˆå§‹åŒ–LLMå’Œç»“æ„åŒ–è¾“å‡ºé“¾"""
    try:
        with open(API_KEY_PATH, "r", encoding='utf-8') as f:
            api_key = f.read().strip()
    except FileNotFoundError:
        raise ValueError(f"é”™è¯¯ï¼šç¯å¢ƒå˜é‡ 'OPENAI_API_KEY' æœªè®¾ç½®ï¼Œä¹Ÿæœªåœ¨ {API_KEY_PATH} æ‰¾åˆ°æ–‡ä»¶ã€‚")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­æä¾› API_KEY_PATH")

    llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.1, api_key=api_key, base_url="https://zzzzapi.com/v1")
    # è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ä¸¤ç§é…ç½®çš„å®¢æˆ·ç«¯
    return {
        "holistic": llm.with_structured_output(SemanticEvaluation),
        "fine_grained": llm.with_structured_output(FineGrainedSemanticEvaluation)
    }

async def initialize_and_fetch_data(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹1: åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼Œå¹¶ä»æ•°æ®åº“è·å–æ•°æ®"""
    print("--- èŠ‚ç‚¹: åˆå§‹åŒ– & è·å–æ•°æ® ---")
    
    # æ ¸å¿ƒä¿®æ­£: ç¡®ä¿è°ƒç”¨æ–°çš„åˆå§‹åŒ–å‡½æ•°ï¼Œå¹¶å°†ç»“æœå­˜å…¥ 'llm_clients' é”®
    state['llm_clients'] = initialize_llm_clients()

    db_manager = MongoDBManager(mongo_uri=state['mongo_uri'], mongo_db_name=state['db_name'])

    # å®šä¹‰æŠ•å½±ä»¥ä»…è·å–æ‰€éœ€å­—æ®µï¼Œæé«˜æ•ˆç‡
    projection_fields = {
        "usecase_key": 1,
        "policies.type": 1,
        "policies.text": 1,
        "policies.reflection_attempts_validation": 1,
    }
    for odrl_field in ODRL_STRATEGIES.values():
        projection_fields[f"policies.{odrl_field}"] = 1

    state['documents'] = await db_manager.fetch_all_rules(
        collection_name=state['collection_name'],
        projection=projection_fields
    )

    if not state['documents']:
        raise ValueError(f"ä»é›†åˆ '{state['collection_name']}' æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£ã€‚è¯·æ£€æŸ¥æ•°æ®åº“å’Œé›†åˆåç§°ã€‚")

    print(f"æˆåŠŸè·å– {len(state['documents'])} ä»½ usecase æ–‡æ¡£ã€‚")
    return state

async def run_syntax_validation_async(odrl_content: Dict, shacl_path: str, total_constraints: int) -> float:
    """
    åœ¨ç‹¬ç«‹çš„çº¿ç¨‹ä¸­å¼‚æ­¥æ‰§è¡ŒCPUå¯†é›†çš„SHACLéªŒè¯ï¼Œå¹¶åº”ç”¨å¹¶å‘æ§åˆ¶ã€‚
    """
    async with cpu_semaphore:
        try:
            # asyncio.to_thread å°†åŒæ­¥å‡½æ•°æ”¾åˆ°ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œï¼Œé˜²æ­¢é˜»å¡
            # validate_odrl_against_shacl æ˜¯ä¸€ä¸ªåŒæ­¥å‡½æ•°
            _, _, num_violations, _ = await asyncio.to_thread(
                validate_odrl_against_shacl, odrl_content, shacl_path
            )
            score = (total_constraints - num_violations) / total_constraints
            return max(0, score)
        except Exception as e:
            print(f"è¯­æ³•éªŒè¯å¤±è´¥ï¼Œå°†è¿”å› 0.0 åˆ†ã€‚é”™è¯¯: {e}")
            return 0.0

async def run_holistic_semantic_evaluation_async(holistic_llm, policy_text: str, odrl_policy_str: str) -> float:
    """
    ä½¿ç”¨ "è£åˆ¤1" (Holistic) LLM è®¡ç®—æ•´ä½“è¯­ä¹‰å¾—åˆ†ã€‚
    """
    async with io_semaphore:
        chain = SEMANTIC_PROMPT | holistic_llm
        try:
            result: SemanticEvaluation = await chain.ainvoke({
                "policy_text": policy_text,
                "odrl_policy_str": odrl_policy_str
            })
            return result.correctly_reflected_units / result.total_semantic_units if result.total_semantic_units > 0 else 0.0
        except Exception as e:
            print(f"LLM è£åˆ¤1 (Holistic) è¯„ä¼°å¤±è´¥: {e}")
            return 0.0

async def run_fine_grained_semantic_evaluation_async(fine_grained_llm, policy_text: str, odrl_policy_str: str) -> float:
    """
    ä½¿ç”¨ "è£åˆ¤2" (Fine-Grained) LLM è®¡ç®—ç²¾ç»†åŒ–è¯­ä¹‰å¾—åˆ†ã€‚
    """
    async with io_semaphore:
        chain = FINE_GRAINED_SEMANTIC_PROMPT | fine_grained_llm
        try:
            result: FineGrainedSemanticEvaluation = await chain.ainvoke({
                "policy_text": policy_text,
                "odrl_policy_str": odrl_policy_str
            })
            
            if not result.identified_units:
                return 0.0

            # æ ¹æ®è¯„åˆ†åè®®è®¡ç®—åˆ†æ•°
            score_map = {
                EvaluationCategory.PERFECTLY_MATCHED: 1.0,
                EvaluationCategory.PARTIALLY_MATCHED: 0.5,
                EvaluationCategory.MISMATCHED: 0.1,
                EvaluationCategory.MISSING: 0.0,
            }
            achieved_score = sum(score_map[unit.evaluation] for unit in result.identified_units)
            total_possible_score = len(result.identified_units)
            
            base_score = achieved_score / total_possible_score if total_possible_score > 0 else 0.0
            
            # åº”ç”¨å¹»è§‰æƒ©ç½š
            hallucination_penalty = len(result.hallucinated_elements) * 0.2 # æ¯ä¸ªå¹»è§‰æ‰£0.2åˆ†
            final_score = base_score - hallucination_penalty
            
            return max(0.0, final_score) # ç¡®ä¿åˆ†æ•°ä¸ä¸ºè´Ÿ
        except Exception as e:
            print(f"LLM è£åˆ¤2 (Fine-Grained) è¯„ä¼°å¤±è´¥: {e}")
            return 0.0

async def evaluate_single_policy(policy: Dict, llm_clients: Dict[str, Any]) -> Dict:
    """
    å¯¹å•ä¸ªpolicyçš„æ‰€æœ‰ç­–ç•¥è¿›è¡Œå¹¶è¡Œçš„è¯­æ³•å’Œè¯­ä¹‰è¯„ä¼°ã€‚
    è¯­ä¹‰è¯„ä¼°ç°åœ¨ç”± "è£åˆ¤1" å’Œ "è£åˆ¤2" å…±åŒå®Œæˆã€‚
    """
    policy_scores = {"syntactic": {}, "semantic": {}}
    syntax_tasks = {}
    # ä»»åŠ¡ç»“æ„: { "strategy_name": (task_j1, task_j2), ... }
    semantic_tasks_by_strategy = defaultdict(list)

    # 1. åˆ›å»ºè¯„ä¼°ä»»åŠ¡
    odrl_type = policy.get("type")
    if odrl_type in TOTAL_CONSTRAINTS_BY_TYPE:
        total_constraints = TOTAL_CONSTRAINTS_BY_TYPE[odrl_type]
        shacl_path = SHACL_PATHS[odrl_type]

        for strategy_name, odrl_field in ODRL_STRATEGIES.items():
            odrl_content = policy.get(odrl_field)
            is_invalid = not odrl_content or (isinstance(odrl_content, dict) and "error" in odrl_content)

            if is_invalid:
                if odrl_content:
                    print(f"æ£€æµ‹åˆ°æ— æ•ˆ ODRL [Policy Text: '{policy.get('text', '')[:30]}...', Strategy: {strategy_name}]. å¾—åˆ†è®°ä¸º 0ã€‚")
                syntax_tasks[strategy_name] = return_zero()
                # ä¸¤ä¸ªè£åˆ¤éƒ½è¿”å›0åˆ†
                semantic_tasks_by_strategy[strategy_name] = [return_zero(), return_zero()]
            else:
                # åˆ›å»ºè¯­æ³•ä»»åŠ¡
                syntax_tasks[strategy_name] = run_syntax_validation_async(
                    odrl_content, shacl_path, total_constraints
                )
                
                # åˆ›å»ºä¸¤ç§è¯­ä¹‰è¯„ä¼°ä»»åŠ¡
                odrl_str = json.dumps(odrl_content)
                task_j1 = run_holistic_semantic_evaluation_async(
                    llm_clients['holistic'], policy["text"], odrl_str
                )
                task_j2 = run_fine_grained_semantic_evaluation_async(
                    llm_clients['fine_grained'], policy["text"], odrl_str
                )
                semantic_tasks_by_strategy[strategy_name] = [task_j1, task_j2]

    # 2. å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    # å°†æ‰€æœ‰ä»»åŠ¡åç¨‹æ”¶é›†åˆ°ä¸€ä¸ªæ‰å¹³åˆ—è¡¨ä¸­
    all_tasks_to_run = list(syntax_tasks.values())
    for tasks_pair in semantic_tasks_by_strategy.values():
        all_tasks_to_run.extend(tasks_pair)

    if not all_tasks_to_run:
        return policy_scores

    all_results = await asyncio.gather(*all_tasks_to_run)

    # 3. è§£æç»“æœ
    result_index = 0
    # è§£æè¯­æ³•å¾—åˆ†
    for strategy_name in syntax_tasks.keys():
        policy_scores["syntactic"][strategy_name] = all_results[result_index]
        result_index += 1

    # è§£æè¯­ä¹‰å¾—åˆ†
    for strategy_name, judge_tasks in semantic_tasks_by_strategy.items():
        if not judge_tasks:
            continue
        
        # è·å–ä¸¤ä¸ªè£åˆ¤çš„å¾—åˆ†
        score_j1 = all_results[result_index]
        score_j2 = all_results[result_index + 1]
        result_index += 2
        
        # è®¡ç®—å¹³å‡åˆ†ä½œä¸ºæœ€ç»ˆè¯­ä¹‰å¾—åˆ†
        policy_scores["semantic"][strategy_name] = (score_j1 + score_j2) / 2

    return policy_scores

async def evaluate_policies(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹2: å¹¶è¡Œè¯„ä¼°æ‰€æœ‰ policies çš„è¯­æ³•å’Œè¯­ä¹‰å¾—åˆ†"""
    print(f"\n--- èŠ‚ç‚¹: è¯„ä¼° Policies (å…± {len(state['documents'])} ä¸ª Usecases) ---")
    # ä¿®æ”¹: ä¼ é€’ llm_clients å­—å…¸
    tasks = [evaluate_single_policy(policy, state['llm_clients']) for doc in state['documents'] for policy in doc.get("policies", [])]
    
    all_policy_scores = await asyncio.gather(*tasks)

    processed_results = []
    policy_counter = 0
    for doc in state['documents']:
        usecase_key = doc['usecase_key']
        category = "unknown"
        if usecase_key.startswith("su_"): category = "simple"
        elif usecase_key.startswith("cu_j_"): category = "concurrent"
        elif usecase_key.startswith("cu_p_"): category = "progressive"

        for policy in doc.get("policies", []):
            processed_results.append({
                "usecase_key": usecase_key, "category": category,
                "reflection_attempts": policy.get("reflection_attempts_validation", 0),
                "scores": all_policy_scores[policy_counter]
            })
            policy_counter += 1

    state['processed_results'] = processed_results
    print(f"è¯„ä¼°å®Œæˆï¼Œå…±å¤„ç† {len(processed_results)} ä¸ª policiesã€‚")
    return state

def aggregate_and_save_results(state: EvaluationState) -> EvaluationState:
    """èŠ‚ç‚¹3: èšåˆæ‰€æœ‰å¾—åˆ†å¹¶ä¿å­˜åˆ°æ–‡ä»¶"""
    print("\n--- èŠ‚ç‚¹: èšåˆç»“æœ & ä¿å­˜æ–‡ä»¶ ---")
    # æŒ‰ usecase_key -> category èšåˆ
    usecase_level_data = defaultdict(lambda: {"category": "", "reflection_attempts": [], "syntactic": defaultdict(list), "semantic": defaultdict(list)})
    for res in state['processed_results']:
        key = res['usecase_key']
        usecase_level_data[key]['category'] = res['category']
        usecase_level_data[key]['reflection_attempts'].append(res['reflection_attempts'])
        for s_name, score in res['scores']['syntactic'].items(): usecase_level_data[key]['syntactic'][s_name].append(score)
        for s_name, score in res['scores']['semantic'].items(): usecase_level_data[key]['semantic'][s_name].append(score)

    usecase_averages = {key: {"category": data['category'],
        "avg_reflection": sum(data['reflection_attempts']) / len(data['reflection_attempts']) if data['reflection_attempts'] else 0,
        "avg_syntactic": {s_name: sum(scores) / len(scores) for s_name, scores in data['syntactic'].items() if scores},
        "avg_semantic": {s_name: sum(scores) / len(scores) for s_name, scores in data['semantic'].items() if scores},
    } for key, data in usecase_level_data.items()}

    category_level_data = defaultdict(lambda: {"reflection_attempts": [], "syntactic": defaultdict(list), "semantic": defaultdict(list)})
    for key, avg_data in usecase_averages.items():
        for category in [avg_data['category'], 'all']: # åŒæ—¶å¡«å……ç‰¹å®šåˆ†ç±»å’Œ'all'åˆ†ç±»
            category_level_data[category]['reflection_attempts'].append(avg_data['avg_reflection'])
            for s_name, score in avg_data['avg_syntactic'].items(): category_level_data[category]['syntactic'][s_name].append(score)
            for s_name, score in avg_data['avg_semantic'].items(): category_level_data[category]['semantic'][s_name].append(score)

    final_results = {}
    for category, data in category_level_data.items():
        final_results[category] = {"average_reflection_attempts": sum(data['reflection_attempts']) / len(data['reflection_attempts']) if data['reflection_attempts'] else 0, "performance_by_strategy": {}}
        for s_name in ODRL_STRATEGIES.keys():
            syn_scores, sem_scores = data['syntactic'][s_name], data['semantic'][s_name]
            final_results[category]["performance_by_strategy"][s_name] = {
                "syntactic_score": f"{sum(syn_scores) / len(syn_scores):.2%}" if syn_scores else "N/A",
                "semantic_score": f"{sum(sem_scores) / len(sem_scores):.2%}" if sem_scores else "N/A",
            }

    output_data = {"metadata": {"source_database": state['db_name'], "source_collection": state['collection_name']}, "results": final_results}

    with open(OUTPUT_RESULTS_PATH, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=4, ensure_ascii=False)

    print(f"èšåˆå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {OUTPUT_RESULTS_PATH}")
    state['final_aggregated_results'] = output_data
    return state

# --- æ„å»º LangGraph å·¥ä½œæµ ---
workflow = StateGraph(EvaluationState)
workflow.add_node("initialize_and_fetch", initialize_and_fetch_data)
workflow.add_node("evaluate_policies", evaluate_policies)
workflow.add_node("aggregate_and_save", aggregate_and_save_results)
workflow.set_entry_point("initialize_and_fetch")
workflow.add_edge("initialize_and_fetch", "evaluate_policies")
workflow.add_edge("evaluate_policies", "aggregate_and_save")
workflow.add_edge("aggregate_and_save", END)
app = workflow.compile()

# --- ä¸»æ‰§è¡Œå‡½æ•° ---
async def main():
    initial_state = {"mongo_uri": MONGO_URI, "db_name": MONGO_DB_NAME, "collection_name": COLLECTION_NAME}
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ LangGraph å·¥ä½œæµ...")
    final_state = await app.ainvoke(initial_state)
    print("\nâœ… å·¥ä½œæµæ‰§è¡Œå®Œæ¯•ã€‚")
    print("\n--- æœ€ç»ˆè¯„ä¼°ç»“æœ ---")
    print(json.dumps(final_state.get('final_aggregated_results', {}), indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())